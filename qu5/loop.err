Traceback (most recent call last):
  File "/home/at-sac/yuzhu/qu5/qu5_pvm_loop.py", line 228, in <module>
    model.optimize(optimizer)
  File "/home/at-sac/yuzhu/qu5/qu5_pvm_loop.py", line 154, in optimize
    loss.backward()  # compute updates for each parameter
  File "/home/at-sac/yuzhu/.conda/envs/new/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/at-sac/yuzhu/.conda/envs/new/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.82 GiB (GPU 0; 39.44 GiB total capacity; 38.26 GiB already allocated; 606.88 MiB free; 38.32 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
srun: error: margpu006: task 0: Exited with exit code 1
