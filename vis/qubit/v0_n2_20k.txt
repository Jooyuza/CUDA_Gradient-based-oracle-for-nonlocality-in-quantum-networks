1693262144.1736188
0 tensor(0.0167, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
10 tensor(0.0042, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20 tensor(0.0019, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
30 tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
40 tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
50 tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
60 tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
70 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
80 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
90 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
100 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
110 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
120 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
130 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
140 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
150 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
160 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
170 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
180 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
190 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
200 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
210 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
220 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
230 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
240 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
250 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
260 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
270 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
280 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
290 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
300 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
310 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
320 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
330 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
340 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
350 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
360 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
370 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
380 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
390 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
400 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
410 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
420 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
430 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
440 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
450 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
460 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
470 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
480 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
490 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
500 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
510 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
520 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
530 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
540 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
550 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
560 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
570 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
580 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
590 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
600 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
610 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
620 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
630 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
640 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
650 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
660 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
670 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
680 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
690 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
700 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
710 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
720 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
730 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
740 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
750 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
760 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
770 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
780 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
790 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
800 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
810 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
820 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
830 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
840 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
850 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
860 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
870 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
880 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
890 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
900 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
910 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
920 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
930 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
940 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
950 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
960 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
970 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
980 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
990 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1000 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1010 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1020 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1030 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1040 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1050 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1060 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1070 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1080 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1090 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1100 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1110 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1120 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1130 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1140 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1150 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1160 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1170 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1180 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1190 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1200 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1210 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1220 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1230 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1240 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1250 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1260 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1270 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1280 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1290 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1300 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1310 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1320 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1330 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1340 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1350 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1360 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1370 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1380 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1390 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1400 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1410 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1420 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1430 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1440 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1450 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1460 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1470 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1480 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1490 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1500 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1510 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1520 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1530 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1540 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1550 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1560 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1570 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1580 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1590 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1600 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1610 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1620 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1630 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1640 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1650 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1660 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1670 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1680 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1690 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1700 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1710 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1720 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1730 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1740 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1750 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1760 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1770 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1780 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1790 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1800 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1810 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1820 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1830 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1840 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1850 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1860 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1870 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1880 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1890 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1900 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1910 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1920 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1930 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1940 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1950 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1960 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1970 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1980 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
1990 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2000 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2010 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2020 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2030 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2040 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2050 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2060 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2070 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2080 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2090 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2100 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2110 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2120 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2130 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2140 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2150 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2160 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2170 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
2180 tensor(9.9920e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2190 tensor(9.9752e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2200 tensor(9.9584e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2210 tensor(9.9417e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2220 tensor(9.9251e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2230 tensor(9.9086e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2240 tensor(9.8922e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2250 tensor(9.8758e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2260 tensor(9.8596e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2270 tensor(9.8434e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2280 tensor(9.8273e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2290 tensor(9.8113e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2300 tensor(9.7953e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2310 tensor(9.7795e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2320 tensor(9.7637e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2330 tensor(9.7479e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2340 tensor(9.7323e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2350 tensor(9.7167e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2360 tensor(9.7012e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2370 tensor(9.6858e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2380 tensor(9.6704e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2390 tensor(9.6552e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2400 tensor(9.6399e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2410 tensor(9.6248e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2420 tensor(9.6097e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2430 tensor(9.5947e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2440 tensor(9.5798e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2450 tensor(9.5649e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2460 tensor(9.5501e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2470 tensor(9.5354e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2480 tensor(9.5207e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2490 tensor(9.5061e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2500 tensor(9.4915e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2510 tensor(9.4770e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2520 tensor(9.4626e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2530 tensor(9.4483e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2540 tensor(9.4340e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2550 tensor(9.4197e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2560 tensor(9.4056e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2570 tensor(9.3914e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2580 tensor(9.3774e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2590 tensor(9.3634e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2600 tensor(9.3495e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2610 tensor(9.3356e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2620 tensor(9.3218e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2630 tensor(9.3080e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2640 tensor(9.2944e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2650 tensor(9.2807e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2660 tensor(9.2672e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2670 tensor(9.2536e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2680 tensor(9.2402e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2690 tensor(9.2268e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2700 tensor(9.2134e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2710 tensor(9.2002e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2720 tensor(9.1869e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2730 tensor(9.1738e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2740 tensor(9.1607e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2750 tensor(9.1476e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2760 tensor(9.1346e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2770 tensor(9.1217e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2780 tensor(9.1088e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2790 tensor(9.0960e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2800 tensor(9.0832e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2810 tensor(9.0705e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2820 tensor(9.0578e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2830 tensor(9.0452e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2840 tensor(9.0327e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2850 tensor(9.0202e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2860 tensor(9.0077e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2870 tensor(8.9954e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2880 tensor(8.9830e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2890 tensor(8.9708e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2900 tensor(8.9586e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2910 tensor(8.9464e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2920 tensor(8.9343e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2930 tensor(8.9223e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2940 tensor(8.9103e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2950 tensor(8.8983e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2960 tensor(8.8865e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2970 tensor(8.8746e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2980 tensor(8.8629e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
2990 tensor(8.8512e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3000 tensor(8.8395e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3010 tensor(8.8279e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3020 tensor(8.8164e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3030 tensor(8.8049e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3040 tensor(8.7934e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3050 tensor(8.7821e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3060 tensor(8.7707e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3070 tensor(8.7595e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3080 tensor(8.7483e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3090 tensor(8.7371e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3100 tensor(8.7260e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3110 tensor(8.7150e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3120 tensor(8.7040e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3130 tensor(8.6930e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3140 tensor(8.6822e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3150 tensor(8.6713e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3160 tensor(8.6606e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3170 tensor(8.6499e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3180 tensor(8.6392e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3190 tensor(8.6286e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3200 tensor(8.6180e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3210 tensor(8.6075e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3220 tensor(8.5971e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3230 tensor(8.5867e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3240 tensor(8.5764e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3250 tensor(8.5661e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3260 tensor(8.5559e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3270 tensor(8.5457e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3280 tensor(8.5356e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3290 tensor(8.5256e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3300 tensor(8.5156e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3310 tensor(8.5056e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3320 tensor(8.4958e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3330 tensor(8.4859e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3340 tensor(8.4761e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3350 tensor(8.4664e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3360 tensor(8.4567e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3370 tensor(8.4471e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3380 tensor(8.4376e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3390 tensor(8.4280e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3400 tensor(8.4186e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3410 tensor(8.4092e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3420 tensor(8.3998e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3430 tensor(8.3905e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3440 tensor(8.3813e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3450 tensor(8.3721e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3460 tensor(8.3630e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3470 tensor(8.3539e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3480 tensor(8.3449e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3490 tensor(8.3359e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3500 tensor(8.3270e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3510 tensor(8.3181e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3520 tensor(8.3093e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3530 tensor(8.3005e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3540 tensor(8.2918e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3550 tensor(8.2831e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3560 tensor(8.2745e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3570 tensor(8.2660e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3580 tensor(8.2575e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3590 tensor(8.2490e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3600 tensor(8.2406e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3610 tensor(8.2323e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3620 tensor(8.2240e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3630 tensor(8.2157e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3640 tensor(8.2075e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3650 tensor(8.1994e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3660 tensor(8.1913e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3670 tensor(8.1832e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3680 tensor(8.1752e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3690 tensor(8.1673e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3700 tensor(8.1594e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3710 tensor(8.1516e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3720 tensor(8.1438e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3730 tensor(8.1360e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3740 tensor(8.1283e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3750 tensor(8.1207e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3760 tensor(8.1131e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3770 tensor(8.1056e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3780 tensor(8.0981e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3790 tensor(8.0906e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3800 tensor(8.0832e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3810 tensor(8.0759e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3820 tensor(8.0686e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3830 tensor(8.0613e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3840 tensor(8.0541e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3850 tensor(8.0470e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3860 tensor(8.0399e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3870 tensor(8.0328e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3880 tensor(8.0258e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3890 tensor(8.0188e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3900 tensor(8.0119e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3910 tensor(8.0050e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3920 tensor(7.9982e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3930 tensor(7.9914e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3940 tensor(7.9847e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3950 tensor(7.9780e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3960 tensor(7.9713e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3970 tensor(7.9647e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3980 tensor(7.9582e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
3990 tensor(7.9517e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4000 tensor(7.9452e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4010 tensor(7.9388e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4020 tensor(7.9324e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4030 tensor(7.9261e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4040 tensor(7.9198e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4050 tensor(7.9136e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4060 tensor(7.9073e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4070 tensor(7.9008e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4080 tensor(7.8960e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4090 tensor(7.9155e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4100 tensor(7.9423e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4110 tensor(7.8916e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4120 tensor(7.9063e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4130 tensor(7.8689e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4140 tensor(7.8626e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4150 tensor(7.8566e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4160 tensor(7.8529e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4170 tensor(7.8477e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4180 tensor(7.8421e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4190 tensor(7.8370e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4200 tensor(7.8312e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4210 tensor(7.8259e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4220 tensor(7.8202e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4230 tensor(7.8149e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4240 tensor(7.8094e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4250 tensor(7.8041e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4260 tensor(7.7987e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4270 tensor(7.7935e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4280 tensor(7.7882e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4290 tensor(7.7830e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4300 tensor(7.7778e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4310 tensor(7.7726e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4320 tensor(7.7675e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4330 tensor(7.7624e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4340 tensor(7.7574e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4350 tensor(7.7524e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4360 tensor(7.7474e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4370 tensor(7.7424e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4380 tensor(7.7375e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4390 tensor(7.7326e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4400 tensor(7.7278e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4410 tensor(7.7229e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4420 tensor(7.7182e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4430 tensor(7.7134e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4440 tensor(7.7087e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4450 tensor(7.7040e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4460 tensor(7.6993e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4470 tensor(7.6947e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4480 tensor(7.6901e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4490 tensor(7.6855e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4500 tensor(7.6809e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4510 tensor(7.6764e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4520 tensor(7.6719e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4530 tensor(7.6674e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4540 tensor(7.6630e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4550 tensor(7.6586e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4560 tensor(7.6542e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4570 tensor(7.6498e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4580 tensor(7.6453e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4590 tensor(7.6413e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4600 tensor(7.6406e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4610 tensor(7.6372e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4620 tensor(7.6288e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4630 tensor(7.8272e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4640 tensor(7.5397e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4650 tensor(7.6468e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4660 tensor(7.6243e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4670 tensor(7.6010e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4680 tensor(7.6178e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4690 tensor(7.5959e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4700 tensor(7.6062e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4710 tensor(7.5942e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4720 tensor(7.5947e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4730 tensor(7.5886e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4740 tensor(7.5855e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4750 tensor(7.5813e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4760 tensor(7.5772e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4770 tensor(7.5735e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4780 tensor(7.5695e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4790 tensor(7.5657e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4800 tensor(7.5618e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4810 tensor(7.5580e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4820 tensor(7.5542e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4830 tensor(7.5504e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4840 tensor(7.5467e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4850 tensor(7.5429e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4860 tensor(7.5392e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4870 tensor(7.5355e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4880 tensor(7.5318e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4890 tensor(7.5281e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4900 tensor(7.5245e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4910 tensor(7.5208e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4920 tensor(7.5172e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4930 tensor(7.5136e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4940 tensor(7.5100e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4950 tensor(7.5064e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4960 tensor(7.5029e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4970 tensor(7.4993e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4980 tensor(7.4958e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
4990 tensor(7.4922e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5000 tensor(7.4887e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5010 tensor(7.4852e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5020 tensor(7.4818e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5030 tensor(7.4783e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5040 tensor(7.4748e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5050 tensor(7.4714e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5060 tensor(7.4680e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5070 tensor(7.4645e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5080 tensor(7.4612e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5090 tensor(7.4577e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5100 tensor(7.4525e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5110 tensor(7.4495e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5120 tensor(7.4986e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5130 tensor(7.4279e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5140 tensor(7.4030e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5150 tensor(7.4462e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5160 tensor(7.4446e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5170 tensor(7.4295e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5180 tensor(7.4360e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5190 tensor(7.4271e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5200 tensor(7.4254e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5210 tensor(7.4232e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5220 tensor(7.4202e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5230 tensor(7.4174e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5240 tensor(7.4137e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5250 tensor(7.4108e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5260 tensor(7.4076e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5270 tensor(7.4043e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5280 tensor(7.4011e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5290 tensor(7.3979e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5300 tensor(7.3948e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5310 tensor(7.3916e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5320 tensor(7.3884e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5330 tensor(7.3853e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5340 tensor(7.3822e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5350 tensor(7.3790e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5360 tensor(7.3759e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5370 tensor(7.3728e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5380 tensor(7.3697e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5390 tensor(7.3666e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5400 tensor(7.3636e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5410 tensor(7.3605e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5420 tensor(7.3574e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5430 tensor(7.3544e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5440 tensor(7.3513e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5450 tensor(7.3483e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5460 tensor(7.3453e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5470 tensor(7.3423e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5480 tensor(7.3392e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5490 tensor(7.3362e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5500 tensor(7.3332e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5510 tensor(7.3303e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5520 tensor(7.3273e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5530 tensor(7.3243e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5540 tensor(7.3214e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5550 tensor(7.3191e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5560 tensor(7.3145e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5570 tensor(7.2977e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5580 tensor(7.3349e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5590 tensor(7.5830e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5600 tensor(7.2872e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5610 tensor(7.1659e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5620 tensor(7.3807e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5630 tensor(7.2800e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5640 tensor(7.2831e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5650 tensor(7.3115e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5660 tensor(7.2821e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5670 tensor(7.2909e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5680 tensor(7.2892e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5690 tensor(7.2820e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5700 tensor(7.2820e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5710 tensor(7.2781e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5720 tensor(7.2752e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5730 tensor(7.2727e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5740 tensor(7.2695e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5750 tensor(7.2669e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5760 tensor(7.2641e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5770 tensor(7.2612e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5780 tensor(7.2584e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5790 tensor(7.2556e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5800 tensor(7.2528e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5810 tensor(7.2500e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5820 tensor(7.2473e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5830 tensor(7.2445e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5840 tensor(7.2417e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5850 tensor(7.2390e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5860 tensor(7.2362e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5870 tensor(7.2335e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5880 tensor(7.2307e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5890 tensor(7.2280e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5900 tensor(7.2253e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5910 tensor(7.2226e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5920 tensor(7.2198e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5930 tensor(7.2171e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5940 tensor(7.2144e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5950 tensor(7.2117e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5960 tensor(7.2090e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5970 tensor(7.2064e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5980 tensor(7.2037e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
5990 tensor(7.2010e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6000 tensor(7.1986e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6010 tensor(7.1961e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6020 tensor(7.1885e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6030 tensor(7.1734e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6040 tensor(7.2251e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6050 tensor(7.5741e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6060 tensor(7.1601e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6070 tensor(7.0880e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6080 tensor(7.2199e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6090 tensor(7.1667e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6100 tensor(7.1691e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6110 tensor(7.1880e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6120 tensor(7.1692e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6130 tensor(7.1706e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6140 tensor(7.1711e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6150 tensor(7.1643e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6160 tensor(7.1630e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6170 tensor(7.1610e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6180 tensor(7.1575e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6190 tensor(7.1552e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6200 tensor(7.1527e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6210 tensor(7.1500e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6220 tensor(7.1475e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6230 tensor(7.1450e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6240 tensor(7.1424e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6250 tensor(7.1399e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6260 tensor(7.1373e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6270 tensor(7.1348e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6280 tensor(7.1323e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6290 tensor(7.1297e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6300 tensor(7.1272e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6310 tensor(7.1247e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6320 tensor(7.1222e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6330 tensor(7.1197e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6340 tensor(7.1172e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6350 tensor(7.1147e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6360 tensor(7.1122e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6370 tensor(7.1097e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6380 tensor(7.1072e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6390 tensor(7.1047e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6400 tensor(7.1022e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6410 tensor(7.0998e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6420 tensor(7.0973e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6430 tensor(7.0948e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6440 tensor(7.0920e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6450 tensor(7.0901e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6460 tensor(7.0941e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6470 tensor(7.0954e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6480 tensor(7.0072e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6490 tensor(7.0224e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6500 tensor(7.1063e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6510 tensor(7.0609e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6520 tensor(7.0855e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6530 tensor(7.0952e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6540 tensor(7.0698e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6550 tensor(7.0731e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6560 tensor(7.0751e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6570 tensor(7.0667e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6580 tensor(7.0650e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6590 tensor(7.0640e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6600 tensor(7.0600e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6610 tensor(7.0575e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6620 tensor(7.0556e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6630 tensor(7.0528e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6640 tensor(7.0502e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6650 tensor(7.0479e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6660 tensor(7.0455e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6670 tensor(7.0430e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6680 tensor(7.0407e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6690 tensor(7.0383e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6700 tensor(7.0359e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6710 tensor(7.0335e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6720 tensor(7.0311e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6730 tensor(7.0287e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6740 tensor(7.0264e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6750 tensor(7.0240e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6760 tensor(7.0216e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6770 tensor(7.0193e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6780 tensor(7.0169e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6790 tensor(7.0146e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6800 tensor(7.0122e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6810 tensor(7.0099e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6820 tensor(7.0075e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6830 tensor(7.0051e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6840 tensor(7.0031e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6850 tensor(7.0004e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6860 tensor(6.9933e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6870 tensor(7.0038e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6880 tensor(7.0813e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6890 tensor(7.1933e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6900 tensor(6.8374e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6910 tensor(6.8131e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6920 tensor(7.0385e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6930 tensor(7.0174e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6940 tensor(6.9639e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6950 tensor(6.9889e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6960 tensor(6.9913e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6970 tensor(6.9780e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6980 tensor(6.9774e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
6990 tensor(6.9775e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7000 tensor(6.9734e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7010 tensor(6.9706e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7020 tensor(6.9689e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7030 tensor(6.9665e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7040 tensor(6.9640e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7050 tensor(6.9617e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7060 tensor(6.9594e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7070 tensor(6.9571e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7080 tensor(6.9548e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7090 tensor(6.9525e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7100 tensor(6.9502e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7110 tensor(6.9479e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7120 tensor(6.9456e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7130 tensor(6.9434e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7140 tensor(6.9411e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7150 tensor(6.9388e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7160 tensor(6.9365e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7170 tensor(6.9343e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7180 tensor(6.9320e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7190 tensor(6.9297e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7200 tensor(6.9275e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7210 tensor(6.9252e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7220 tensor(6.9230e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7230 tensor(6.9207e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7240 tensor(6.9184e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7250 tensor(6.9162e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7260 tensor(6.9140e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7270 tensor(6.9117e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7280 tensor(6.9094e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7290 tensor(6.9077e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7300 tensor(6.9054e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7310 tensor(6.8924e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7320 tensor(6.8904e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7330 tensor(7.1873e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7340 tensor(6.9991e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7350 tensor(6.8309e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7360 tensor(6.8098e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7370 tensor(6.9262e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7380 tensor(6.9167e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7390 tensor(6.8776e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7400 tensor(6.8870e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7410 tensor(6.8948e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7420 tensor(6.8859e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7430 tensor(6.8816e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7440 tensor(6.8821e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7450 tensor(6.8798e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7460 tensor(6.8765e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7470 tensor(6.8746e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7480 tensor(6.8727e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7490 tensor(6.8703e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7500 tensor(6.8680e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7510 tensor(6.8659e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7520 tensor(6.8637e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7530 tensor(6.8614e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7540 tensor(6.8593e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7550 tensor(6.8571e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7560 tensor(6.8549e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7570 tensor(6.8527e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7580 tensor(6.8505e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7590 tensor(6.8483e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7600 tensor(6.8461e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7610 tensor(6.8440e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7620 tensor(6.8418e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7630 tensor(6.8396e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7640 tensor(6.8374e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7650 tensor(6.8353e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7660 tensor(6.8331e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7670 tensor(6.8310e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7680 tensor(6.8288e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7690 tensor(6.8267e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7700 tensor(6.8244e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7710 tensor(6.8221e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7720 tensor(6.8215e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7730 tensor(6.8198e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7740 tensor(6.7793e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7750 tensor(6.7881e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7760 tensor(7.0038e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7770 tensor(6.8301e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7780 tensor(6.7346e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7790 tensor(6.8116e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7800 tensor(6.8418e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7810 tensor(6.8060e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7820 tensor(6.7957e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7830 tensor(6.8060e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7840 tensor(6.8051e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7850 tensor(6.7979e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7860 tensor(6.7961e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7870 tensor(6.7957e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7880 tensor(6.7929e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7890 tensor(6.7902e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7900 tensor(6.7884e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7910 tensor(6.7864e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7920 tensor(6.7841e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7930 tensor(6.7820e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7940 tensor(6.7799e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7950 tensor(6.7778e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7960 tensor(6.7757e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7970 tensor(6.7736e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7980 tensor(6.7715e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
7990 tensor(6.7694e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8000 tensor(6.7673e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8010 tensor(6.7652e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8020 tensor(6.7631e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8030 tensor(6.7611e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8040 tensor(6.7590e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8050 tensor(6.7569e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8060 tensor(6.7549e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8070 tensor(6.7527e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8080 tensor(6.7506e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8090 tensor(6.7500e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8100 tensor(6.7429e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8110 tensor(6.7346e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8120 tensor(6.7790e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8130 tensor(6.8864e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8140 tensor(6.5800e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8150 tensor(6.5250e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8160 tensor(6.7571e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8170 tensor(6.8119e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8180 tensor(6.7157e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8190 tensor(6.7093e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8200 tensor(6.7478e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8210 tensor(6.7400e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8220 tensor(6.7226e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8230 tensor(6.7252e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8240 tensor(6.7276e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8250 tensor(6.7230e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8260 tensor(6.7198e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8270 tensor(6.7187e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8280 tensor(6.7168e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8290 tensor(6.7144e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8300 tensor(6.7124e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8310 tensor(6.7104e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8320 tensor(6.7084e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8330 tensor(6.7063e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8340 tensor(6.7043e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8350 tensor(6.7023e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8360 tensor(6.7002e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8370 tensor(6.6982e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8380 tensor(6.6962e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8390 tensor(6.6941e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8400 tensor(6.6921e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8410 tensor(6.6901e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8420 tensor(6.6881e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8430 tensor(6.6861e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8440 tensor(6.6840e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8450 tensor(6.6820e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8460 tensor(6.6800e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8470 tensor(6.6780e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8480 tensor(6.6760e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8490 tensor(6.6741e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8500 tensor(6.6718e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8510 tensor(6.6693e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8520 tensor(6.6732e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8530 tensor(6.6709e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8540 tensor(6.6034e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8550 tensor(6.5671e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8560 tensor(6.6368e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8570 tensor(6.6652e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8580 tensor(6.6727e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8590 tensor(6.6601e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8600 tensor(6.6560e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8610 tensor(6.6553e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8620 tensor(6.6524e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8630 tensor(6.6512e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8640 tensor(6.6494e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8650 tensor(6.6469e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8660 tensor(6.6447e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8670 tensor(6.6429e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8680 tensor(6.6410e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8690 tensor(6.6390e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8700 tensor(6.6370e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8710 tensor(6.6350e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8720 tensor(6.6330e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8730 tensor(6.6310e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8740 tensor(6.6291e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8750 tensor(6.6270e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8760 tensor(6.6252e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8770 tensor(6.6229e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8780 tensor(6.6217e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8790 tensor(6.6184e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8800 tensor(6.6171e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8810 tensor(6.6242e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8820 tensor(6.5778e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8830 tensor(6.6399e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8840 tensor(6.7089e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8850 tensor(6.5646e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8860 tensor(6.5787e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8870 tensor(6.6233e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8880 tensor(6.6156e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8890 tensor(6.5962e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8900 tensor(6.5983e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8910 tensor(6.6035e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8920 tensor(6.5983e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8930 tensor(6.5942e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8940 tensor(6.5936e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8950 tensor(6.5922e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8960 tensor(6.5898e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8970 tensor(6.5876e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8980 tensor(6.5859e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
8990 tensor(6.5839e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9000 tensor(6.5820e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9010 tensor(6.5799e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9020 tensor(6.5781e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9030 tensor(6.5760e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9040 tensor(6.5745e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9050 tensor(6.5716e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9060 tensor(6.5712e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9070 tensor(6.5682e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9080 tensor(6.5607e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9090 tensor(6.5941e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9100 tensor(6.5270e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9110 tensor(6.3589e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9120 tensor(6.5025e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9130 tensor(6.6075e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9140 tensor(6.5815e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9150 tensor(6.5388e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9160 tensor(6.5489e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9170 tensor(6.5605e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9180 tensor(6.5517e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9190 tensor(6.5462e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9200 tensor(6.5464e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9210 tensor(6.5459e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9220 tensor(6.5433e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9230 tensor(6.5406e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9240 tensor(6.5392e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9250 tensor(6.5375e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9260 tensor(6.5354e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9270 tensor(6.5335e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9280 tensor(6.5315e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9290 tensor(6.5298e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9300 tensor(6.5277e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9310 tensor(6.5260e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9320 tensor(6.5238e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9330 tensor(6.5222e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9340 tensor(6.5208e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9350 tensor(6.5148e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9360 tensor(6.5282e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9370 tensor(6.4763e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9380 tensor(6.4859e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9390 tensor(6.5621e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9400 tensor(6.5104e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9410 tensor(6.5029e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9420 tensor(6.5032e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9430 tensor(6.5107e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9440 tensor(6.5048e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9450 tensor(6.4995e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9460 tensor(6.5000e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9470 tensor(6.4991e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9480 tensor(6.4962e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9490 tensor(6.4947e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9500 tensor(6.4922e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9510 tensor(6.4916e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9520 tensor(6.4880e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9530 tensor(6.4887e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9540 tensor(6.4824e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9550 tensor(6.4879e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9560 tensor(6.4749e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9570 tensor(6.4694e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9580 tensor(6.4994e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9590 tensor(6.4151e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9600 tensor(6.4348e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9610 tensor(6.4849e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9620 tensor(6.4858e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9630 tensor(6.4688e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9640 tensor(6.4647e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9650 tensor(6.4691e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9660 tensor(6.4667e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9670 tensor(6.4631e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9680 tensor(6.4611e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9690 tensor(6.4606e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9700 tensor(6.4585e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9710 tensor(6.4564e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9720 tensor(6.4546e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9730 tensor(6.4529e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9740 tensor(6.4511e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9750 tensor(6.4492e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9760 tensor(6.4473e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9770 tensor(6.4460e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9780 tensor(6.4425e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9790 tensor(6.4459e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9800 tensor(6.4321e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9810 tensor(6.4466e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9820 tensor(6.3984e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9830 tensor(6.3959e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9840 tensor(6.3845e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9850 tensor(6.4382e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9860 tensor(6.4531e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9870 tensor(6.4266e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9880 tensor(6.4237e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9890 tensor(6.4267e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9900 tensor(6.4262e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9910 tensor(6.4228e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9920 tensor(6.4203e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9930 tensor(6.4198e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9940 tensor(6.4182e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9950 tensor(6.4159e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9960 tensor(6.4142e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9970 tensor(6.4125e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9980 tensor(6.4108e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
9990 tensor(6.4090e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10000 tensor(6.4072e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10010 tensor(6.4055e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10020 tensor(6.4039e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10030 tensor(6.4016e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10040 tensor(6.4015e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10050 tensor(6.3960e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10060 tensor(6.4010e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10070 tensor(6.3875e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10080 tensor(6.3652e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10090 tensor(6.4142e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10100 tensor(6.3838e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10110 tensor(6.3884e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10120 tensor(6.3873e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10130 tensor(6.3863e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10140 tensor(6.3820e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10150 tensor(6.3847e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10160 tensor(6.3820e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10170 tensor(6.3790e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10180 tensor(6.3781e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10190 tensor(6.3765e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10200 tensor(6.3748e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10210 tensor(6.3734e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10220 tensor(6.3710e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10230 tensor(6.3701e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10240 tensor(6.3676e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10250 tensor(6.3668e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10260 tensor(6.3641e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10270 tensor(6.3629e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10280 tensor(6.3630e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10290 tensor(6.3535e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10300 tensor(6.3772e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10310 tensor(6.3527e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10320 tensor(6.3293e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10330 tensor(6.3618e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10340 tensor(6.3697e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10350 tensor(6.3471e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10360 tensor(6.3472e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10370 tensor(6.3616e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10380 tensor(6.3559e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10390 tensor(6.3422e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10400 tensor(6.3398e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10410 tensor(6.3413e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10420 tensor(6.3404e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10430 tensor(6.3382e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10440 tensor(6.3355e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10450 tensor(6.3346e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10460 tensor(6.3326e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10470 tensor(6.3311e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10480 tensor(6.3304e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10490 tensor(6.3248e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10500 tensor(6.3349e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10510 tensor(6.3139e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10520 tensor(6.3303e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10530 tensor(6.3370e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10540 tensor(6.3268e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10550 tensor(6.3157e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10560 tensor(6.3217e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10570 tensor(6.3147e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10580 tensor(6.3146e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10590 tensor(6.3126e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10600 tensor(6.3108e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10610 tensor(6.3101e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10620 tensor(6.3074e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10630 tensor(6.3068e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10640 tensor(6.3042e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10650 tensor(6.3029e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10660 tensor(6.3128e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10670 tensor(6.3142e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10680 tensor(6.3101e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10690 tensor(6.2875e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10700 tensor(6.2992e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10710 tensor(6.2929e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10720 tensor(6.2897e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10730 tensor(6.2874e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10740 tensor(6.2968e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10750 tensor(6.2889e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10760 tensor(6.2861e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10770 tensor(6.2843e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10780 tensor(6.2825e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10790 tensor(6.2824e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10800 tensor(6.2796e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10810 tensor(6.2789e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10820 tensor(6.2761e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10830 tensor(6.2760e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10840 tensor(6.2729e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10850 tensor(6.2727e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10860 tensor(6.2697e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10870 tensor(6.2662e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10880 tensor(6.2744e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10890 tensor(6.2598e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10900 tensor(6.2694e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10910 tensor(6.2631e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10920 tensor(6.2615e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10930 tensor(6.2558e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10940 tensor(6.2591e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10950 tensor(6.2564e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10960 tensor(6.2562e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10970 tensor(6.2533e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10980 tensor(6.2519e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
10990 tensor(6.2498e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11000 tensor(6.2499e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11010 tensor(6.2612e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11020 tensor(6.2610e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11030 tensor(6.2438e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11040 tensor(6.2409e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11050 tensor(6.2343e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11060 tensor(6.2429e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11070 tensor(6.2381e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11080 tensor(6.2372e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11090 tensor(6.2338e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11100 tensor(6.2339e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11110 tensor(6.2309e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11120 tensor(6.2314e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11130 tensor(6.2281e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11140 tensor(6.2278e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11150 tensor(6.2246e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11160 tensor(6.2229e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11170 tensor(6.2204e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11180 tensor(6.2168e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11190 tensor(6.2186e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11200 tensor(6.2137e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11210 tensor(6.2170e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11220 tensor(6.2138e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11230 tensor(6.2140e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11240 tensor(6.2116e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11250 tensor(6.2108e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11260 tensor(6.2085e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11270 tensor(6.2070e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11280 tensor(6.2045e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11290 tensor(6.2023e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11300 tensor(6.2017e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11310 tensor(6.1987e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11320 tensor(6.2007e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11330 tensor(6.1984e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11340 tensor(6.1970e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11350 tensor(6.1952e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11360 tensor(6.2076e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11370 tensor(6.2261e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11380 tensor(6.2091e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11390 tensor(6.1889e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11400 tensor(6.1818e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11410 tensor(6.1824e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11420 tensor(6.1839e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11430 tensor(6.1852e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11440 tensor(6.1825e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11450 tensor(6.1788e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11460 tensor(6.1775e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11470 tensor(6.1765e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11480 tensor(6.1759e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11490 tensor(6.1750e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11500 tensor(6.1734e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11510 tensor(6.1720e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11520 tensor(6.1700e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11530 tensor(6.1688e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11540 tensor(6.1673e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11550 tensor(6.1670e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11560 tensor(6.1643e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11570 tensor(6.1602e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11580 tensor(6.1569e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11590 tensor(6.1518e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11600 tensor(6.1546e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11610 tensor(6.1544e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11620 tensor(6.1554e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11630 tensor(6.1537e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11640 tensor(6.1533e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11650 tensor(6.1513e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11660 tensor(6.1512e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11670 tensor(6.1491e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11680 tensor(6.1475e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11690 tensor(6.1441e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11700 tensor(6.1377e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11710 tensor(6.1360e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11720 tensor(6.1314e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11730 tensor(6.1347e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11740 tensor(6.1351e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11750 tensor(6.1377e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11760 tensor(6.1359e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11770 tensor(6.1358e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11780 tensor(6.1335e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11790 tensor(6.1323e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11800 tensor(6.1308e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11810 tensor(6.1417e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11820 tensor(6.1621e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11830 tensor(6.1450e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11840 tensor(6.1267e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11850 tensor(6.1158e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11860 tensor(6.1110e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11870 tensor(6.1057e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11880 tensor(6.0934e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11890 tensor(6.1028e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11900 tensor(6.1120e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11910 tensor(6.1176e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11920 tensor(6.1146e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11930 tensor(6.1125e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11940 tensor(6.1115e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11950 tensor(6.1104e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11960 tensor(6.1092e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11970 tensor(6.1083e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11980 tensor(6.1061e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
11990 tensor(6.1059e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12000 tensor(6.1029e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12010 tensor(6.1027e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12020 tensor(6.0989e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12030 tensor(6.0923e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12040 tensor(6.0929e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12050 tensor(6.0760e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12060 tensor(6.0802e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12070 tensor(6.0854e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12080 tensor(6.0933e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12090 tensor(6.0916e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12100 tensor(6.0915e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12110 tensor(6.0880e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12120 tensor(6.0877e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12130 tensor(6.0859e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12140 tensor(6.0844e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12150 tensor(6.0841e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12160 tensor(6.0797e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12170 tensor(6.0833e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12180 tensor(6.0735e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12190 tensor(6.0657e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12200 tensor(6.0639e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12210 tensor(6.0532e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12220 tensor(6.0640e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12230 tensor(6.0701e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12240 tensor(6.0739e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12250 tensor(6.0702e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12260 tensor(6.0823e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12270 tensor(6.1522e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12280 tensor(6.1405e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12290 tensor(6.0882e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12300 tensor(6.0575e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12310 tensor(6.0488e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12320 tensor(6.0530e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12330 tensor(6.0604e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12340 tensor(6.0521e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12350 tensor(6.0564e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12360 tensor(6.0322e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12370 tensor(6.0314e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12380 tensor(6.0430e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12390 tensor(6.0558e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12400 tensor(6.0536e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12410 tensor(6.0525e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12420 tensor(6.0485e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12430 tensor(6.0484e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12440 tensor(6.0467e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12450 tensor(6.0459e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12460 tensor(6.0454e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12470 tensor(6.0412e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12480 tensor(6.0446e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12490 tensor(6.0354e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12500 tensor(6.0323e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12510 tensor(6.0254e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12520 tensor(6.0067e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12530 tensor(6.0173e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12540 tensor(6.0182e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12550 tensor(6.0292e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12560 tensor(6.0305e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12570 tensor(6.0337e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12580 tensor(6.0290e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12590 tensor(6.0303e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12600 tensor(6.0262e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12610 tensor(6.0272e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12620 tensor(6.0244e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12630 tensor(6.0201e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12640 tensor(6.0229e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12650 tensor(6.0117e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12660 tensor(6.0178e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12670 tensor(6.0009e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12680 tensor(5.9983e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12690 tensor(6.0041e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12700 tensor(6.0085e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12710 tensor(6.0139e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12720 tensor(6.0132e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12730 tensor(6.0143e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12740 tensor(6.0096e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12750 tensor(6.0120e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12760 tensor(6.0063e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12770 tensor(6.0098e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12780 tensor(6.0030e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12790 tensor(5.9977e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12800 tensor(5.9978e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12810 tensor(5.9823e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12820 tensor(5.9910e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12830 tensor(6.0138e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12840 tensor(6.0248e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12850 tensor(6.0122e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12860 tensor(6.0043e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12870 tensor(5.9928e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12880 tensor(5.9952e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12890 tensor(5.9898e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12900 tensor(5.9884e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12910 tensor(5.9879e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12920 tensor(5.9753e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12930 tensor(5.9814e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12940 tensor(5.9672e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12950 tensor(5.9755e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12960 tensor(5.9744e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12970 tensor(5.9814e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12980 tensor(5.9826e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
12990 tensor(5.9839e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13000 tensor(5.9838e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13010 tensor(5.9801e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13020 tensor(5.9826e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13030 tensor(5.9763e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13040 tensor(6.0745e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13050 tensor(5.9633e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13060 tensor(5.9205e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13070 tensor(5.9455e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13080 tensor(5.9334e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13090 tensor(5.9398e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13100 tensor(5.9603e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13110 tensor(5.9785e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13120 tensor(5.9778e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13130 tensor(5.9764e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13140 tensor(5.9713e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13150 tensor(5.9709e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13160 tensor(5.9700e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13170 tensor(5.9839e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13180 tensor(5.9912e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13190 tensor(5.9804e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13200 tensor(5.9686e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13210 tensor(5.9643e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13220 tensor(5.9629e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13230 tensor(5.9613e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13240 tensor(5.9654e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13250 tensor(5.9544e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13260 tensor(5.9437e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13270 tensor(5.9239e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13280 tensor(5.8765e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13290 tensor(5.8955e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13300 tensor(5.9290e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13310 tensor(5.9390e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13320 tensor(5.9413e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13330 tensor(5.9520e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13340 tensor(5.9553e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13350 tensor(5.9556e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13360 tensor(5.9610e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13370 tensor(5.9694e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13380 tensor(5.9656e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13390 tensor(5.9545e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13400 tensor(5.9495e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13410 tensor(5.9450e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13420 tensor(5.9413e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13430 tensor(5.9595e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13440 tensor(5.9263e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13450 tensor(6.3471e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13460 tensor(5.5806e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13470 tensor(5.0884e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13480 tensor(7.7002e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13490 tensor(4.5317e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13500 tensor(5.6566e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13510 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13520 tensor(6.5425e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13530 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13540 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13550 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13560 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13570 tensor(8.9017e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13580 tensor(7.5446e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13590 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13600 tensor(8.3833e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13610 tensor(7.4903e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13620 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13630 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13640 tensor(9.9631e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
13650 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13660 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13670 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13680 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13690 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13700 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13710 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13720 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13730 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13740 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13750 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13760 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13770 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13780 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13790 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13800 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13810 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13820 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13830 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13840 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13850 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13860 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13870 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13880 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13890 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13900 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13910 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13920 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13930 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13940 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13950 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13960 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13970 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13980 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
13990 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14000 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14010 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14020 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14030 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14040 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14050 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14060 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14070 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14080 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14090 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14100 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14110 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14120 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14130 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14140 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14150 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14160 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14170 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14180 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14190 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14200 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14210 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14220 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14230 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14240 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14250 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14260 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14270 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14280 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14290 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14300 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14310 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14320 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14330 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14340 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14350 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14360 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14370 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14380 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14390 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14400 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14410 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14420 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14430 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14440 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14450 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14460 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14470 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14480 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14490 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14500 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14510 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14520 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14530 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14540 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14550 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14560 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14570 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14580 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14590 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14600 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14610 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14620 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14630 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14640 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14650 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14660 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14670 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14680 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14690 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14700 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14710 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14720 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14730 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14740 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14750 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14760 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14770 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14780 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14790 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14800 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14810 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14820 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14830 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14840 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14850 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14860 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14870 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14880 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14890 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14900 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14910 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14920 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14930 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14940 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14950 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14960 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14970 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14980 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
14990 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15000 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15010 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15020 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15030 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15040 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15050 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15060 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15070 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15080 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15090 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15100 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15110 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15120 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15130 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15140 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15150 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15160 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15170 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15180 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15190 tensor(7.9166e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15200 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15210 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15220 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15230 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15240 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15250 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15260 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15270 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15280 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15290 tensor(7.9351e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15300 tensor(4.0187e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15310 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15320 tensor(7.0827e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15330 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15340 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15350 tensor(8.9079e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15360 tensor(7.4655e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15370 tensor(7.5057e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15380 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15390 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15400 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15410 tensor(9.3268e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15420 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15430 tensor(9.4314e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15440 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15450 tensor(9.2124e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15460 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15470 tensor(8.7645e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15480 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15490 tensor(8.4026e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15500 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15510 tensor(8.1798e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15520 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15530 tensor(8.0834e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15540 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15550 tensor(8.0866e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15560 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15570 tensor(8.1609e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15580 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15590 tensor(8.2811e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15600 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15610 tensor(8.4274e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15620 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15630 tensor(8.5849e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15640 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15650 tensor(8.7438e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15660 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15670 tensor(8.8976e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15680 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15690 tensor(9.0426e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15700 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15710 tensor(9.1768e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15720 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15730 tensor(9.2995e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15740 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15750 tensor(9.4107e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15760 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15770 tensor(9.5110e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15780 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15790 tensor(9.6009e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15800 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15810 tensor(9.6814e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15820 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15830 tensor(9.7533e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15840 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15850 tensor(9.8176e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15860 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15870 tensor(9.8749e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15880 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15890 tensor(9.9261e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15900 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15910 tensor(9.9719e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
15920 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15930 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15940 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15950 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15960 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15970 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15980 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
15990 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16000 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16010 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16020 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16030 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16040 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16050 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16060 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16070 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16080 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16090 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16100 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16110 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16120 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16130 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16140 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16150 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16160 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16170 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16180 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16190 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16200 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16210 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16220 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16230 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16240 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16250 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16260 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16270 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16280 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16290 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16300 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16310 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16320 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16330 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16340 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16350 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16360 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16370 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16380 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16390 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16400 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16410 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16420 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16430 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16440 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16450 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16460 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16470 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16480 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16490 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16500 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16510 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16520 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16530 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16540 tensor(8.9313e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
16550 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16560 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16570 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16580 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16590 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16600 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16610 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16620 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16630 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16640 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16650 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16660 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16670 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16680 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16690 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16700 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16710 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16720 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16730 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16740 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16750 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16760 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16770 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16780 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16790 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16800 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16810 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16820 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16830 tensor(8.4525e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
16840 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16850 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16860 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16870 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16880 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16890 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16900 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16910 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16920 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16930 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16940 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16950 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16960 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16970 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
16980 tensor(7.5416e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
16990 tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17000 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17010 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17020 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17030 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17040 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17050 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17060 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17070 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17080 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17090 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17100 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17110 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17120 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17130 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17140 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17150 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17160 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17170 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17180 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17190 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17200 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17210 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17220 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17230 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17240 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17250 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17260 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17270 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17280 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17290 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17300 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17310 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17320 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17330 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17340 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17350 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17360 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17370 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17380 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17390 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17400 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17410 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17420 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17430 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17440 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17450 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17460 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17470 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17480 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17490 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17500 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17510 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17520 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17530 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17540 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17550 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17560 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17570 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17580 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17590 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17600 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17610 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17620 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17630 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17640 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17650 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17660 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17670 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17680 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17690 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17700 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17710 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17720 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17730 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17740 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17750 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17760 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17770 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17780 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17790 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17800 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17810 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17820 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17830 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17840 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17850 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17860 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17870 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17880 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17890 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17900 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17910 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17920 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17930 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17940 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17950 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17960 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17970 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17980 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
17990 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18000 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18010 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18020 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18030 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18040 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18050 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18060 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18070 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18080 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18090 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18100 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18110 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18120 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18130 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18140 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18150 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18160 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18170 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18180 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18190 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18200 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18210 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18220 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18230 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18240 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18250 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18260 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18270 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18280 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18290 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18300 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18310 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18320 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18330 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18340 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18350 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18360 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18370 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18380 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18390 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18400 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18410 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18420 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18430 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18440 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18450 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18460 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18470 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18480 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18490 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18500 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18510 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18520 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18530 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18540 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18550 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18560 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18570 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18580 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18590 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18600 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18610 tensor(7.8300e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
18620 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18630 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18640 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18650 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18660 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18670 tensor(9.2198e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
18680 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18690 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18700 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18710 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18720 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18730 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18740 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18750 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18760 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18770 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18780 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18790 tensor(9.0023e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
18800 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18810 tensor(9.2454e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
18820 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18830 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18840 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18850 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18860 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18870 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18880 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18890 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18900 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18910 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18920 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18930 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18940 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18950 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18960 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18970 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18980 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
18990 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19000 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19010 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19020 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19030 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19040 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19050 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19060 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19070 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19080 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19090 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19100 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19110 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19120 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19130 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19140 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19150 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19160 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19170 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19180 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19190 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19200 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19210 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19220 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19230 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19240 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19250 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19260 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19270 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19280 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19290 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19300 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19310 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19320 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19330 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19340 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19350 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19360 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19370 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19380 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19390 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19400 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19410 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19420 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19430 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19440 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19450 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19460 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19470 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19480 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19490 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19500 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19510 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19520 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19530 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19540 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19550 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19560 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19570 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19580 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19590 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19600 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19610 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19620 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19630 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19640 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19650 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19660 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19670 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19680 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19690 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19700 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19710 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19720 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19730 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19740 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19750 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19760 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19770 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19780 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19790 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19800 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19810 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19820 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19830 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19840 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19850 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19860 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19870 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19880 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19890 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19900 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19910 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19920 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19930 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19940 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19950 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19960 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
19970 tensor(9.8942e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
19980 tensor(7.6460e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
19990 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20000 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20010 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20020 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20030 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20040 tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20050 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20060 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20070 tensor(7.8249e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
20080 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20090 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20100 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20110 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20120 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20130 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20140 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20150 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20160 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20170 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20180 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20190 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20200 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20210 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20220 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20230 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20240 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20250 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20260 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20270 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20280 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20290 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20300 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20310 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20320 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20330 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20340 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20350 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20360 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20370 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20380 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20390 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20400 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20410 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20420 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20430 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20440 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20450 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20460 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20470 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20480 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20490 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20500 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20510 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20520 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20530 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20540 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20550 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20560 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20570 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20580 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20590 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20600 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20610 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20620 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20630 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20640 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20650 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20660 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20670 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20680 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20690 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20700 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20710 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20720 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20730 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20740 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20750 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20760 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20770 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20780 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20790 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20800 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20810 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20820 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20830 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20840 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20850 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20860 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20870 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20880 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20890 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20900 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20910 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20920 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20930 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20940 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20950 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20960 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20970 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20980 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
20990 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21000 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21010 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21020 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21030 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21040 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21050 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21060 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21070 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21080 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21090 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21100 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21110 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21120 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21130 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21140 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21150 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21160 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21170 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21180 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21190 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21200 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21210 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21220 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21230 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21240 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21250 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21260 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21270 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21280 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21290 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21300 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21310 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21320 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21330 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21340 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21350 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21360 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21370 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21380 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21390 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21400 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21410 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21420 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21430 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21440 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21450 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21460 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21470 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21480 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21490 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21500 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21510 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21520 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21530 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21540 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21550 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21560 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21570 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21580 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21590 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21600 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21610 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21620 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21630 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21640 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21650 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21660 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21670 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21680 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21690 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21700 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21710 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21720 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21730 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21740 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21750 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21760 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21770 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21780 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21790 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21800 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21810 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21820 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21830 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21840 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21850 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21860 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21870 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21880 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21890 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21900 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21910 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21920 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21930 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21940 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21950 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21960 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21970 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21980 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
21990 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22000 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22010 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22020 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22030 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22040 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22050 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22060 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22070 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22080 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22090 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22100 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22110 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22120 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22130 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22140 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22150 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22160 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22170 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22180 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22190 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22200 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22210 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22220 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22230 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22240 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22250 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22260 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22270 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22280 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22290 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22300 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22310 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22320 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22330 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22340 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22350 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22360 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22370 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22380 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22390 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22400 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22410 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22420 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22430 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22440 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22450 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22460 tensor(4.6832e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
22470 tensor(8.7742e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
22480 tensor(4.5298e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
22490 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22500 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22510 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22520 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22530 tensor(8.3641e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
22540 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22550 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22560 tensor(9.9160e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
22570 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22580 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22590 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22600 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22610 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22620 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22630 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22640 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22650 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22660 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22670 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22680 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22690 tensor(9.5777e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
22700 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22710 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22720 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22730 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22740 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22750 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22760 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22770 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22780 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22790 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22800 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22810 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22820 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22830 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22840 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22850 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22860 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22870 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22880 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22890 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22900 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22910 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22920 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22930 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22940 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22950 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22960 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22970 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22980 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
22990 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23000 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23010 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23020 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23030 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23040 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23050 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23060 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23070 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23080 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23090 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23100 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23110 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23120 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23130 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23140 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23150 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23160 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23170 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23180 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23190 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23200 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23210 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23220 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23230 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23240 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23250 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23260 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23270 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23280 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23290 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23300 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23310 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23320 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23330 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23340 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23350 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23360 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23370 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23380 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23390 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23400 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23410 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23420 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23430 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23440 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23450 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23460 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23470 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23480 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23490 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23500 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23510 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23520 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23530 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23540 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23550 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23560 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23570 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23580 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23590 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23600 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23610 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23620 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23630 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23640 tensor(9.9505e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
23650 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23660 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23670 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23680 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23690 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23700 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23710 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23720 tensor(9.9802e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
23730 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23740 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23750 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23760 tensor(9.9773e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
23770 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23780 tensor(9.9795e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
23790 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23800 tensor(9.9680e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
23810 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23820 tensor(9.9516e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
23830 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23840 tensor(9.9438e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
23850 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23860 tensor(9.9173e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
23870 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23880 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23890 tensor(9.3260e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
23900 tensor(9.4145e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
23910 tensor(9.6857e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
23920 tensor(9.9584e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
23930 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23940 tensor(9.7592e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
23950 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23960 tensor(9.9708e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
23970 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
23980 tensor(9.8589e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
23990 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24000 tensor(9.8835e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24010 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24020 tensor(9.8325e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24030 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24040 tensor(9.7916e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24050 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24060 tensor(9.8036e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24070 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24080 tensor(9.8050e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24090 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24100 tensor(9.7821e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24110 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24120 tensor(9.7598e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24130 tensor(9.9907e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24140 tensor(9.7467e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24150 tensor(9.9672e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24160 tensor(9.7408e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24170 tensor(9.9365e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24180 tensor(9.7374e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24190 tensor(9.8960e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24200 tensor(9.7325e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24210 tensor(9.8423e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24220 tensor(9.7015e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24230 tensor(9.7709e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24240 tensor(9.5884e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24250 tensor(9.6109e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24260 tensor(9.2933e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24270 tensor(9.2193e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24280 tensor(8.6107e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24290 tensor(8.4441e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24300 tensor(7.4086e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24310 tensor(7.7548e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24320 tensor(6.9784e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24330 tensor(6.8979e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24340 tensor(6.7909e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24350 tensor(6.4582e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24360 tensor(6.5826e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24370 tensor(6.2039e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24380 tensor(6.3984e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24390 tensor(6.0526e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24400 tensor(6.2238e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24410 tensor(5.9555e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24420 tensor(6.0710e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24430 tensor(5.8594e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24440 tensor(5.9500e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24450 tensor(5.7482e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24460 tensor(6.3822e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24470 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24480 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24490 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24500 tensor(4.7583e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24510 tensor(7.5470e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24520 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24530 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24540 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24550 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24560 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24570 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24580 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24590 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24600 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24610 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24620 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24630 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24640 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24650 tensor(5.7464e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24660 tensor(6.0149e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24670 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24680 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24690 tensor(9.3176e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24700 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24710 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24720 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24730 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24740 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24750 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24760 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24770 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24780 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24790 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24800 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24810 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24820 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24830 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24840 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24850 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24860 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24870 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24880 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24890 tensor(9.9858e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24900 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24910 tensor(9.9512e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24920 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24930 tensor(9.9172e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24940 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24950 tensor(9.8841e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24960 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24970 tensor(9.8516e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
24980 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
24990 tensor(9.8197e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25000 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
25010 tensor(9.7885e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25020 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
25030 tensor(9.7578e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25040 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
25050 tensor(9.7276e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25060 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
25070 tensor(9.6978e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25080 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
25090 tensor(9.6683e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25100 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
25110 tensor(9.6392e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25120 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
25130 tensor(9.6104e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25140 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
25150 tensor(9.5818e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25160 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
25170 tensor(9.5534e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25180 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
25190 tensor(9.5253e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25200 tensor(9.9974e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25210 tensor(9.4974e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25220 tensor(9.9774e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25230 tensor(9.4697e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25240 tensor(9.9575e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25250 tensor(9.4423e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25260 tensor(9.9379e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25270 tensor(9.4151e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25280 tensor(9.9183e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25290 tensor(9.3881e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25300 tensor(9.8988e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25310 tensor(9.3614e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25320 tensor(9.8793e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25330 tensor(9.3351e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25340 tensor(9.8598e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25350 tensor(9.3090e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25360 tensor(9.8402e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25370 tensor(9.2834e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25380 tensor(9.8204e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25390 tensor(9.2581e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25400 tensor(9.8006e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25410 tensor(9.2333e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25420 tensor(9.7805e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25430 tensor(9.2090e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25440 tensor(9.7603e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25450 tensor(9.1852e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25460 tensor(9.7398e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25470 tensor(9.1619e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25480 tensor(9.7191e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25490 tensor(9.1392e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25500 tensor(9.6981e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25510 tensor(9.1171e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25520 tensor(9.6769e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25530 tensor(9.0955e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25540 tensor(9.6555e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25550 tensor(9.0746e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25560 tensor(9.6338e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25570 tensor(9.0543e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25580 tensor(9.6119e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25590 tensor(9.0346e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25600 tensor(9.5897e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25610 tensor(9.0156e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25620 tensor(9.5673e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25630 tensor(8.9973e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25640 tensor(9.5445e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25650 tensor(8.9798e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25660 tensor(9.5214e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25670 tensor(8.9632e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25680 tensor(9.4974e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25690 tensor(8.9479e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25700 tensor(9.4720e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25710 tensor(8.9344e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25720 tensor(9.4440e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25730 tensor(8.9237e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25740 tensor(9.4115e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25750 tensor(8.9160e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25760 tensor(9.3735e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25770 tensor(8.9076e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25780 tensor(9.3343e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25790 tensor(8.8860e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25800 tensor(9.3075e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25810 tensor(8.8331e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25820 tensor(9.3036e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25830 tensor(8.7497e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25840 tensor(9.3030e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25850 tensor(8.6625e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25860 tensor(9.2861e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25870 tensor(8.5717e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25880 tensor(9.2653e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25890 tensor(8.4713e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25900 tensor(9.2376e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25910 tensor(8.3740e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25920 tensor(9.2017e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25930 tensor(8.2814e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25940 tensor(9.1671e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25950 tensor(8.1892e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25960 tensor(9.1371e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25970 tensor(8.1004e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25980 tensor(9.1055e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
25990 tensor(8.0182e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26000 tensor(9.0715e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26010 tensor(7.9389e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26020 tensor(9.0369e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26030 tensor(7.8598e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26040 tensor(9.0008e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26050 tensor(7.7798e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26060 tensor(8.9618e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26070 tensor(7.6976e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26080 tensor(8.9169e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26090 tensor(7.6126e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26100 tensor(8.8612e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26110 tensor(7.5264e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26120 tensor(8.7871e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26130 tensor(7.4420e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26140 tensor(8.6880e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26150 tensor(7.3613e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26160 tensor(8.5632e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26170 tensor(7.2773e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26180 tensor(8.4187e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26190 tensor(7.1672e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26200 tensor(8.2530e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26210 tensor(7.0169e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26220 tensor(7.9749e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26230 tensor(6.9775e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26240 tensor(7.4755e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26250 tensor(7.0077e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26260 tensor(7.1197e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26270 tensor(6.8775e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26280 tensor(6.8861e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26290 tensor(6.7668e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26300 tensor(6.6515e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26310 tensor(6.6827e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26320 tensor(6.4605e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26330 tensor(6.5873e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26340 tensor(6.3143e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26350 tensor(6.4913e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26360 tensor(6.1944e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26370 tensor(6.4000e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26380 tensor(6.0951e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26390 tensor(6.3118e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26400 tensor(6.0122e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26410 tensor(6.2277e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26420 tensor(5.9401e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26430 tensor(6.1498e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26440 tensor(5.8727e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26450 tensor(6.0807e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26460 tensor(5.8039e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26470 tensor(6.0235e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26480 tensor(5.7270e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26490 tensor(5.9833e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26500 tensor(5.6327e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26510 tensor(5.9743e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26520 tensor(5.5008e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26530 tensor(6.0480e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26540 tensor(4.1598e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26550 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26560 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26570 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26580 tensor(7.5746e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26590 tensor(7.1928e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26600 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26610 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26620 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26630 tensor(7.4658e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26640 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26650 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26660 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26670 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26680 tensor(8.9546e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26690 tensor(8.7206e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26700 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26710 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26720 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26730 tensor(8.6349e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26740 tensor(7.6292e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26750 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26760 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26770 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26780 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26790 tensor(6.7656e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26800 tensor(5.2495e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26810 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26820 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26830 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26840 tensor(6.3712e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26850 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26860 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26870 tensor(2.4191e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
26880 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26890 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26900 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26910 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26920 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26930 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26940 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26950 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26960 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26970 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26980 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
26990 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27000 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27010 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27020 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27030 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27040 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27050 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27060 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27070 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27080 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27090 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27100 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27110 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27120 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27130 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27140 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27150 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27160 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27170 tensor(4.7561e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27180 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27190 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27200 tensor(7.8451e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27210 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27220 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27230 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27240 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27250 tensor(9.9695e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27260 tensor(9.9510e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27270 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27280 tensor(9.9073e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27290 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27300 tensor(9.8667e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27310 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27320 tensor(9.8308e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27330 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27340 tensor(9.7973e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27350 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27360 tensor(9.7648e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27370 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27380 tensor(9.7340e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27390 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27400 tensor(9.7042e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27410 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27420 tensor(9.6756e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27430 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
27440 tensor(9.6479e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27450 tensor(9.9768e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27460 tensor(9.6211e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27470 tensor(9.9464e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27480 tensor(9.5952e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27490 tensor(9.9165e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27500 tensor(9.5699e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27510 tensor(9.8872e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27520 tensor(9.5454e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27530 tensor(9.8585e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27540 tensor(9.5215e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27550 tensor(9.8303e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27560 tensor(9.4981e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27570 tensor(9.8025e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27580 tensor(9.4753e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27590 tensor(9.7753e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27600 tensor(9.4530e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27610 tensor(9.7485e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27620 tensor(9.4312e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27630 tensor(9.7221e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27640 tensor(9.4098e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27650 tensor(9.6960e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27660 tensor(9.3888e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27670 tensor(9.6704e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27680 tensor(9.3682e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27690 tensor(9.6451e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27700 tensor(9.3479e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27710 tensor(9.6202e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27720 tensor(9.3280e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27730 tensor(9.5956e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27740 tensor(9.3084e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27750 tensor(9.5713e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27760 tensor(9.2891e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27770 tensor(9.5473e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27780 tensor(9.2701e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27790 tensor(9.5236e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27800 tensor(9.2514e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27810 tensor(9.5002e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27820 tensor(9.2330e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27830 tensor(9.4770e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27840 tensor(9.2148e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27850 tensor(9.4540e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27860 tensor(9.1969e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27870 tensor(9.4312e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27880 tensor(9.1792e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27890 tensor(9.4087e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27900 tensor(9.1619e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27910 tensor(9.3862e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27920 tensor(9.1448e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27930 tensor(9.3638e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27940 tensor(9.1281e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27950 tensor(9.3414e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27960 tensor(9.1119e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27970 tensor(9.3187e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27980 tensor(9.0963e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
27990 tensor(9.2955e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28000 tensor(9.0816e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28010 tensor(9.2713e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28020 tensor(9.0682e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28030 tensor(9.2453e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28040 tensor(9.0566e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28050 tensor(9.2163e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28060 tensor(9.0473e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28070 tensor(9.1829e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28080 tensor(9.0401e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28090 tensor(9.1436e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28100 tensor(9.0334e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28110 tensor(9.0974e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28120 tensor(9.0228e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28130 tensor(9.0452e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28140 tensor(9.0015e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28150 tensor(8.9905e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28160 tensor(8.9631e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28170 tensor(8.9395e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28180 tensor(8.9059e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28190 tensor(8.8972e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28200 tensor(8.8379e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28210 tensor(8.8608e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28220 tensor(8.7728e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28230 tensor(8.8243e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28240 tensor(8.7167e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28250 tensor(8.7867e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28260 tensor(8.6689e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28270 tensor(8.7477e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28280 tensor(8.6281e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28290 tensor(8.7060e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28300 tensor(8.5934e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28310 tensor(8.6598e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28320 tensor(8.5633e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28330 tensor(8.6069e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28340 tensor(8.5335e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28350 tensor(8.5433e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28360 tensor(8.4922e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28370 tensor(8.4541e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28380 tensor(8.4063e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28390 tensor(8.2918e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28400 tensor(8.2008e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28410 tensor(8.0701e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28420 tensor(7.8697e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28430 tensor(8.0905e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28440 tensor(7.3932e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28450 tensor(7.9832e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28460 tensor(7.2203e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28470 tensor(7.8039e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28480 tensor(7.0176e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28490 tensor(7.6075e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28500 tensor(6.8790e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28510 tensor(7.4369e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28520 tensor(6.7551e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28530 tensor(7.2761e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28540 tensor(6.6454e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28550 tensor(7.1357e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28560 tensor(6.5499e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28570 tensor(7.0111e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28580 tensor(6.4649e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28590 tensor(6.9002e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28600 tensor(6.3897e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28610 tensor(6.8015e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28620 tensor(6.3229e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28630 tensor(6.7133e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28640 tensor(6.2633e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28650 tensor(6.6344e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28660 tensor(6.2099e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28670 tensor(6.5639e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28680 tensor(6.1618e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28690 tensor(6.5006e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28700 tensor(6.1183e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28710 tensor(6.4438e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28720 tensor(6.0787e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28730 tensor(6.3926e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28740 tensor(6.0427e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28750 tensor(6.3463e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28760 tensor(6.0097e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28770 tensor(6.3044e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28780 tensor(5.9794e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28790 tensor(6.2665e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28800 tensor(5.9506e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28810 tensor(6.2382e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28820 tensor(5.6466e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28830 tensor(9.1674e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28840 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
28850 tensor(9.2547e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28860 tensor(8.0497e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28870 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
28880 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
28890 tensor(8.6536e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28900 tensor(8.6040e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28910 tensor(9.7634e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28920 tensor(8.8192e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28930 tensor(9.2025e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28940 tensor(8.7652e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28950 tensor(9.2331e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28960 tensor(8.7216e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28970 tensor(9.1047e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28980 tensor(8.6862e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
28990 tensor(9.0492e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29000 tensor(8.6427e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29010 tensor(8.9803e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29020 tensor(8.6071e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29030 tensor(8.9238e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29040 tensor(8.5698e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29050 tensor(8.8699e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29060 tensor(8.5351e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29070 tensor(8.8203e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29080 tensor(8.5013e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29090 tensor(8.7737e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29100 tensor(8.4691e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29110 tensor(8.7296e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29120 tensor(8.4382e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29130 tensor(8.6879e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29140 tensor(8.4085e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29150 tensor(8.6481e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29160 tensor(8.3801e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29170 tensor(8.6101e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29180 tensor(8.3527e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29190 tensor(8.5737e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29200 tensor(8.3264e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29210 tensor(8.5388e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29220 tensor(8.3011e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29230 tensor(8.5053e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29240 tensor(8.2767e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29250 tensor(8.4729e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29260 tensor(8.2531e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29270 tensor(8.4418e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29280 tensor(8.2304e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29290 tensor(8.4117e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29300 tensor(8.2085e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29310 tensor(8.3827e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29320 tensor(8.1873e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29330 tensor(8.3545e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29340 tensor(8.1668e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29350 tensor(8.3273e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29360 tensor(8.1471e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29370 tensor(8.3009e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29380 tensor(8.1279e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29390 tensor(8.2753e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29400 tensor(8.1095e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29410 tensor(8.2503e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29420 tensor(8.0916e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29430 tensor(8.2261e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29440 tensor(8.0743e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29450 tensor(8.2024e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29460 tensor(8.0576e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29470 tensor(8.1793e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29480 tensor(8.0415e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29490 tensor(8.1565e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29500 tensor(8.0258e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29510 tensor(8.1337e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29520 tensor(8.0105e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29530 tensor(8.1105e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29540 tensor(7.9949e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29550 tensor(8.0858e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29560 tensor(7.9779e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29570 tensor(8.0571e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29580 tensor(7.9560e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29590 tensor(8.0188e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29600 tensor(7.9196e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29610 tensor(7.9571e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29620 tensor(7.8413e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29630 tensor(7.8353e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29640 tensor(7.6517e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29650 tensor(7.6314e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29660 tensor(7.3383e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29670 tensor(7.5425e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29680 tensor(7.1363e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29690 tensor(7.1909e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29700 tensor(7.0237e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29710 tensor(7.0092e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29720 tensor(6.9109e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29730 tensor(6.8637e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29740 tensor(6.7797e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29750 tensor(6.7395e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29760 tensor(6.6612e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29770 tensor(6.6324e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29780 tensor(6.5465e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29790 tensor(6.5334e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29800 tensor(6.4273e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29810 tensor(6.4335e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29820 tensor(6.2939e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29830 tensor(6.3298e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29840 tensor(6.1367e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29850 tensor(6.2679e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29860 tensor(5.9310e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29870 tensor(6.3150e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29880 tensor(5.7268e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29890 tensor(6.2373e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29900 tensor(5.6816e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29910 tensor(6.1529e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29920 tensor(5.6027e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29930 tensor(6.0843e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29940 tensor(5.5463e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29950 tensor(6.0214e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29960 tensor(5.4903e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29970 tensor(5.9654e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29980 tensor(5.4408e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
29990 tensor(5.9147e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30000 tensor(5.3945e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30010 tensor(5.8687e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30020 tensor(5.3515e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30030 tensor(6.6168e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30040 tensor(9.8916e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30050 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
30060 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
30070 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
30080 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
30090 tensor(9.0076e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30100 tensor(9.6227e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30110 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
30120 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
30130 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
30140 tensor(9.9447e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30150 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
30160 tensor(9.8150e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30170 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
30180 tensor(9.7299e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30190 tensor(9.9445e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30200 tensor(9.6299e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30210 tensor(9.8410e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30220 tensor(9.5476e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30230 tensor(9.7498e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30240 tensor(9.4667e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30250 tensor(9.6633e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30260 tensor(9.3934e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30270 tensor(9.5806e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30280 tensor(9.3244e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30290 tensor(9.5027e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30300 tensor(9.2602e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30310 tensor(9.4286e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30320 tensor(9.2002e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30330 tensor(9.3584e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30340 tensor(9.1442e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30350 tensor(9.2919e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30360 tensor(9.0918e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30370 tensor(9.2289e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30380 tensor(9.0431e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30390 tensor(9.1694e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30400 tensor(8.9977e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30410 tensor(9.1132e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30420 tensor(8.9556e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30430 tensor(9.0601e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30440 tensor(8.9168e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30450 tensor(9.0101e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30460 tensor(8.8811e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30470 tensor(8.9630e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30480 tensor(8.8485e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30490 tensor(8.9185e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30500 tensor(8.8191e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30510 tensor(8.8764e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30520 tensor(8.7928e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30530 tensor(8.8361e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30540 tensor(8.7696e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30550 tensor(8.7971e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30560 tensor(8.7496e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30570 tensor(8.7583e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30580 tensor(8.7325e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30590 tensor(8.7189e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30600 tensor(8.7173e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30610 tensor(8.6774e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30620 tensor(8.7014e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30630 tensor(8.6318e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30640 tensor(8.6787e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30650 tensor(8.5769e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30660 tensor(8.6375e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30670 tensor(8.4973e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30680 tensor(8.5545e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30690 tensor(8.3595e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30700 tensor(8.3933e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30710 tensor(8.1410e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30720 tensor(8.1349e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30730 tensor(7.9277e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30740 tensor(7.8329e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30750 tensor(7.8718e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30760 tensor(7.5242e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30770 tensor(7.8176e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30780 tensor(7.3962e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30790 tensor(7.6991e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30800 tensor(7.2747e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30810 tensor(7.6007e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30820 tensor(7.1838e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30830 tensor(7.5050e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30840 tensor(7.1067e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30850 tensor(7.4141e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30860 tensor(7.0423e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30870 tensor(7.3307e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30880 tensor(6.9871e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30890 tensor(7.2543e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30900 tensor(6.9381e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30910 tensor(7.1850e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30920 tensor(6.8940e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30930 tensor(7.1221e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30940 tensor(6.8538e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30950 tensor(7.0649e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30960 tensor(6.8167e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30970 tensor(7.0126e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30980 tensor(6.7822e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
30990 tensor(6.9647e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31000 tensor(6.7499e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31010 tensor(6.9205e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31020 tensor(6.7194e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31030 tensor(6.8796e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31040 tensor(6.6902e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31050 tensor(6.8415e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31060 tensor(6.6622e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31070 tensor(6.8060e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31080 tensor(6.6350e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31090 tensor(6.7727e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31100 tensor(6.6085e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31110 tensor(6.7413e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31120 tensor(6.5825e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31130 tensor(6.7115e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31140 tensor(6.5569e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31150 tensor(6.6832e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31160 tensor(6.5316e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31170 tensor(6.6560e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31180 tensor(6.5067e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31190 tensor(6.6299e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31200 tensor(6.4820e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31210 tensor(6.6046e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31220 tensor(6.4577e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31230 tensor(6.5802e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31240 tensor(6.4337e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31250 tensor(6.5564e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31260 tensor(6.4100e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31270 tensor(6.5333e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31280 tensor(6.3866e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31290 tensor(6.5107e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31300 tensor(6.3637e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31310 tensor(6.4886e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31320 tensor(6.3412e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31330 tensor(6.4670e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31340 tensor(6.3191e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31350 tensor(6.4459e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31360 tensor(6.2975e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31370 tensor(6.4253e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31380 tensor(6.2764e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31390 tensor(6.4051e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31400 tensor(6.2558e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31410 tensor(6.3853e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31420 tensor(6.2357e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31430 tensor(6.3661e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31440 tensor(6.2162e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31450 tensor(6.3473e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31460 tensor(6.1971e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31470 tensor(6.3289e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31480 tensor(6.1786e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31490 tensor(6.3111e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31500 tensor(6.1607e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31510 tensor(6.2937e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31520 tensor(6.1432e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31530 tensor(6.2767e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31540 tensor(6.1263e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31550 tensor(6.2603e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31560 tensor(6.1099e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31570 tensor(6.2443e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31580 tensor(6.0941e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31590 tensor(6.2287e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31600 tensor(6.0787e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31610 tensor(6.2137e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31620 tensor(6.0638e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31630 tensor(6.1991e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31640 tensor(6.0494e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31650 tensor(6.1849e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31660 tensor(6.0354e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31670 tensor(6.1712e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31680 tensor(6.0219e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31690 tensor(6.1579e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31700 tensor(5.9962e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31710 tensor(6.7252e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31720 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31730 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31740 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31750 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31760 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31770 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31780 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31790 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31800 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31810 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31820 tensor(9.4674e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31830 tensor(9.8502e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31840 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31850 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31860 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31870 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31880 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31890 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31900 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31910 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31920 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31930 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31940 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31950 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31960 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31970 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
31980 tensor(9.9986e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
31990 tensor(9.9289e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32000 tensor(9.9148e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32010 tensor(9.8534e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32020 tensor(9.8360e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32030 tensor(9.7829e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32040 tensor(9.7629e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32050 tensor(9.7162e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32060 tensor(9.6945e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32070 tensor(9.6531e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32080 tensor(9.6302e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32090 tensor(9.5933e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32100 tensor(9.5696e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32110 tensor(9.5364e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32120 tensor(9.5123e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32130 tensor(9.4822e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32140 tensor(9.4579e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32150 tensor(9.4306e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32160 tensor(9.4062e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32170 tensor(9.3813e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32180 tensor(9.3568e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32190 tensor(9.3343e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32200 tensor(9.3097e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32210 tensor(9.2893e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32220 tensor(9.2647e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32230 tensor(9.2463e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32240 tensor(9.2215e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32250 tensor(9.2052e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32260 tensor(9.1802e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32270 tensor(9.1658e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32280 tensor(9.1404e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32290 tensor(9.1281e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32300 tensor(9.1022e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32310 tensor(9.0920e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32320 tensor(9.0655e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32330 tensor(9.0573e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32340 tensor(9.0301e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32350 tensor(9.0242e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32360 tensor(8.9960e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32370 tensor(8.9924e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32380 tensor(8.9631e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32390 tensor(8.9619e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32400 tensor(8.9313e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32410 tensor(8.9327e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32420 tensor(8.9005e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32430 tensor(8.9048e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32440 tensor(8.8707e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32450 tensor(8.8782e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32460 tensor(8.8417e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32470 tensor(8.8526e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32480 tensor(8.8136e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32490 tensor(8.8278e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32500 tensor(8.7861e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32510 tensor(8.8033e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32520 tensor(8.7594e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32530 tensor(8.7775e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32540 tensor(8.7333e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32550 tensor(8.7473e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32560 tensor(8.7073e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32570 tensor(8.7060e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32580 tensor(8.6775e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32590 tensor(8.6412e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32600 tensor(8.6294e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32610 tensor(8.5271e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32620 tensor(8.5332e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32630 tensor(8.3136e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32640 tensor(8.4238e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32650 tensor(8.0098e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32660 tensor(8.2502e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32670 tensor(7.9587e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32680 tensor(7.9872e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32690 tensor(7.8385e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32700 tensor(7.7962e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32710 tensor(7.6855e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32720 tensor(7.6665e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32730 tensor(7.5558e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32740 tensor(7.5352e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32750 tensor(7.4283e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32760 tensor(7.4137e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32770 tensor(7.2905e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32780 tensor(7.2873e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32790 tensor(7.1199e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32800 tensor(7.1600e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32810 tensor(6.8935e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32820 tensor(7.1520e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32830 tensor(6.5656e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32840 tensor(7.1709e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32850 tensor(6.4666e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32860 tensor(7.0094e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32870 tensor(6.3879e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32880 tensor(6.9335e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32890 tensor(6.3136e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32900 tensor(6.8415e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32910 tensor(6.2511e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32920 tensor(6.7688e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32930 tensor(6.1934e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32940 tensor(6.7003e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32950 tensor(6.1413e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32960 tensor(6.6395e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32970 tensor(6.0933e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32980 tensor(6.5839e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
32990 tensor(6.0490e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33000 tensor(6.5331e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33010 tensor(6.0079e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33020 tensor(6.4865e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33030 tensor(5.9697e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33040 tensor(6.4435e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33050 tensor(5.9340e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33060 tensor(6.4038e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33070 tensor(5.9007e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33080 tensor(6.3670e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33090 tensor(5.8694e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33100 tensor(6.3341e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33110 tensor(5.7566e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33120 tensor(9.7575e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33130 tensor(9.1300e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33140 tensor(9.5526e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33150 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
33160 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
33170 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
33180 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
33190 tensor(5.3496e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33200 tensor(8.4009e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33210 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
33220 tensor(6.1934e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33230 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
33240 tensor(5.6422e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33250 tensor(6.5960e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33260 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
33270 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
33280 tensor(8.3976e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33290 tensor(8.9675e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33300 tensor(9.1536e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33310 tensor(9.0613e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33320 tensor(8.6847e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33330 tensor(8.9279e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33340 tensor(8.7263e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33350 tensor(8.8183e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33360 tensor(8.5908e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33370 tensor(8.7290e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33380 tensor(8.5280e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33390 tensor(8.6362e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33400 tensor(8.4460e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33410 tensor(8.5541e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33420 tensor(8.3785e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33430 tensor(8.4739e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33440 tensor(8.3122e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33450 tensor(8.3998e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33460 tensor(8.2509e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33470 tensor(8.3293e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33480 tensor(8.1932e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33490 tensor(8.2630e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33500 tensor(8.1392e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33510 tensor(8.2005e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33520 tensor(8.0885e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33530 tensor(8.1415e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33540 tensor(8.0410e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33550 tensor(8.0856e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33560 tensor(7.9967e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33570 tensor(8.0326e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33580 tensor(7.9557e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33590 tensor(7.9819e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33600 tensor(7.9182e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33610 tensor(7.9328e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33620 tensor(7.8845e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33630 tensor(7.8842e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33640 tensor(7.8550e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33650 tensor(7.8348e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33660 tensor(7.8296e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33670 tensor(7.7831e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33680 tensor(7.8072e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33690 tensor(7.7276e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33700 tensor(7.7850e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33710 tensor(7.6668e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33720 tensor(7.7571e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33730 tensor(7.5977e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33740 tensor(7.7160e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33750 tensor(7.5155e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33760 tensor(7.6542e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33770 tensor(7.4181e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33780 tensor(7.5671e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33790 tensor(7.3199e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33800 tensor(7.4438e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33810 tensor(7.2391e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33820 tensor(7.2870e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33830 tensor(7.1388e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33840 tensor(7.1368e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33850 tensor(7.0201e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33860 tensor(6.9996e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33870 tensor(6.9280e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33880 tensor(6.8742e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33890 tensor(6.8752e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33900 tensor(6.7578e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33910 tensor(6.8252e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33920 tensor(6.6680e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33930 tensor(6.7680e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33940 tensor(6.5953e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33950 tensor(6.7114e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33960 tensor(6.5328e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33970 tensor(6.6565e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33980 tensor(6.4776e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
33990 tensor(6.6042e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34000 tensor(6.4265e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34010 tensor(6.5565e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34020 tensor(6.3765e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34030 tensor(6.5139e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34040 tensor(6.3261e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34050 tensor(6.4751e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34060 tensor(6.2747e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34070 tensor(6.4384e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34080 tensor(6.2217e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34090 tensor(6.4025e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34100 tensor(6.1671e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34110 tensor(6.3661e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34120 tensor(6.1116e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34130 tensor(6.3280e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34140 tensor(6.0567e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34150 tensor(6.2878e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34160 tensor(6.0033e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34170 tensor(6.2457e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34180 tensor(5.9519e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34190 tensor(6.2026e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34200 tensor(5.9028e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34210 tensor(6.1591e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34220 tensor(5.8559e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34230 tensor(6.1161e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34240 tensor(5.8111e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34250 tensor(6.0739e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34260 tensor(5.7683e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34270 tensor(6.0329e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34280 tensor(5.7275e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34290 tensor(5.9933e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34300 tensor(5.6884e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34310 tensor(5.9551e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34320 tensor(5.6511e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34330 tensor(5.9185e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34340 tensor(5.6155e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34350 tensor(5.8833e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34360 tensor(5.5815e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34370 tensor(5.8496e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34380 tensor(5.5491e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34390 tensor(5.8173e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34400 tensor(5.5181e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34410 tensor(5.7864e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34420 tensor(5.4885e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34430 tensor(5.7569e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34440 tensor(5.4603e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34450 tensor(5.7287e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34460 tensor(5.4334e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34470 tensor(5.7017e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34480 tensor(5.4077e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34490 tensor(5.6759e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34500 tensor(5.3831e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34510 tensor(5.6513e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34520 tensor(5.3597e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34530 tensor(5.6277e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34540 tensor(5.3373e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34550 tensor(5.6053e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34560 tensor(5.3159e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34570 tensor(5.5838e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34580 tensor(5.2955e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34590 tensor(5.5633e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34600 tensor(5.2759e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34610 tensor(5.5461e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34620 tensor(5.2559e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34630 tensor(7.2796e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34640 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
34650 tensor(8.4481e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34660 tensor(7.6105e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34670 tensor(5.6241e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34680 tensor(9.0733e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34690 tensor(9.2500e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34700 tensor(8.0347e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34710 tensor(9.8886e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34720 tensor(8.7591e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34730 tensor(9.8181e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34740 tensor(9.5155e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34750 tensor(9.6273e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34760 tensor(8.9791e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34770 tensor(9.4155e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34780 tensor(9.0387e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34790 tensor(9.2787e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34800 tensor(8.7136e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34810 tensor(9.2595e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34820 tensor(8.5878e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34830 tensor(9.1136e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34840 tensor(8.5291e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34850 tensor(8.9917e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34860 tensor(8.4534e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34870 tensor(8.8844e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34880 tensor(8.3870e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34890 tensor(8.7875e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34900 tensor(8.3232e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34910 tensor(8.6975e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34920 tensor(8.2658e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34930 tensor(8.6121e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34940 tensor(8.2136e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34950 tensor(8.5303e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34960 tensor(8.1666e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34970 tensor(8.4511e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34980 tensor(8.1246e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
34990 tensor(8.3736e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35000 tensor(8.0875e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35010 tensor(8.2972e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35020 tensor(8.0550e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35030 tensor(8.2211e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35040 tensor(8.0266e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35050 tensor(8.1448e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35060 tensor(8.0016e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35070 tensor(8.0680e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35080 tensor(7.9791e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35090 tensor(7.9909e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35100 tensor(7.9576e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35110 tensor(7.9142e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35120 tensor(7.9351e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35130 tensor(7.8391e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35140 tensor(7.9096e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35150 tensor(7.7672e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35160 tensor(7.8796e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35170 tensor(7.6997e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35180 tensor(7.8447e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35190 tensor(7.6368e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35200 tensor(7.8053e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35210 tensor(7.5782e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35220 tensor(7.7624e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35230 tensor(7.5234e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35240 tensor(7.7170e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35250 tensor(7.4721e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35260 tensor(7.6700e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35270 tensor(7.4236e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35280 tensor(7.6219e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35290 tensor(7.3776e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35300 tensor(7.5736e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35310 tensor(7.3339e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35320 tensor(7.5254e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35330 tensor(7.2920e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35340 tensor(7.4778e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35350 tensor(7.2518e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35360 tensor(7.4312e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35370 tensor(7.2127e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35380 tensor(7.3861e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35390 tensor(7.1741e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35400 tensor(7.3429e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35410 tensor(7.1349e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35420 tensor(7.3020e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35430 tensor(7.0939e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35440 tensor(7.2632e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35450 tensor(7.0498e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35460 tensor(7.2259e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35470 tensor(7.0026e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35480 tensor(7.1887e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35490 tensor(6.9541e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35500 tensor(7.1497e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35510 tensor(6.9076e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35520 tensor(7.1067e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35530 tensor(6.8656e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35540 tensor(7.0597e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35550 tensor(6.8280e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35560 tensor(7.0108e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35570 tensor(6.7935e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35580 tensor(6.9622e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35590 tensor(6.7615e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35600 tensor(6.9152e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35610 tensor(6.7318e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35620 tensor(6.8701e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35630 tensor(6.7044e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35640 tensor(6.8270e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35650 tensor(6.6792e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35660 tensor(6.7855e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35670 tensor(6.6560e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35680 tensor(6.7452e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35690 tensor(6.6347e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35700 tensor(6.7057e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35710 tensor(6.6149e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35720 tensor(6.6664e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35730 tensor(6.5965e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35740 tensor(6.6265e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35750 tensor(6.5785e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35760 tensor(6.6061e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35770 tensor(6.3529e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35780 tensor(6.7634e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35790 tensor(6.9306e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35800 tensor(6.5085e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35810 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
35820 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
35830 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
35840 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
35850 tensor(5.1094e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35860 tensor(5.8626e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35870 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
35880 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
35890 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
35900 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
35910 tensor(6.3876e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35920 tensor(7.2578e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35930 tensor(7.9990e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35940 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
35950 tensor(9.5055e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35960 tensor(8.9524e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35970 tensor(9.8968e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35980 tensor(9.5780e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
35990 tensor(9.3115e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36000 tensor(8.7761e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36010 tensor(9.4214e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36020 tensor(8.8202e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36030 tensor(9.4139e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36040 tensor(8.6891e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36050 tensor(9.2832e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36060 tensor(8.6118e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36070 tensor(9.2059e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36080 tensor(8.5676e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36090 tensor(9.0907e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36100 tensor(8.5331e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36110 tensor(9.0064e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36120 tensor(8.4949e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36130 tensor(8.9266e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36140 tensor(8.4630e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36150 tensor(8.8560e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36160 tensor(8.4327e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36170 tensor(8.7923e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36180 tensor(8.4052e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36190 tensor(8.7343e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36200 tensor(8.3800e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36210 tensor(8.6813e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36220 tensor(8.3569e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36230 tensor(8.6325e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36240 tensor(8.3356e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36250 tensor(8.5873e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36260 tensor(8.3160e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36270 tensor(8.5451e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36280 tensor(8.2980e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36290 tensor(8.5054e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36300 tensor(8.2814e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36310 tensor(8.4679e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36320 tensor(8.2657e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36330 tensor(8.4322e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36340 tensor(8.2505e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36350 tensor(8.3980e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36360 tensor(8.2347e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36370 tensor(8.3648e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36380 tensor(8.2171e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36390 tensor(8.3317e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36400 tensor(8.1962e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36410 tensor(8.2967e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36420 tensor(8.1702e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36430 tensor(8.2572e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36440 tensor(8.1376e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36450 tensor(8.2099e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36460 tensor(8.0990e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36470 tensor(8.1529e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36480 tensor(8.0578e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36490 tensor(8.0862e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36500 tensor(8.0170e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36510 tensor(8.0135e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36520 tensor(7.9729e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36530 tensor(7.9410e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36540 tensor(7.9219e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36550 tensor(7.8663e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36560 tensor(7.8639e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36570 tensor(7.7847e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36580 tensor(7.7959e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36590 tensor(7.6989e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36600 tensor(7.7141e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36610 tensor(7.6134e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36620 tensor(7.6198e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36630 tensor(7.5290e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36640 tensor(7.5136e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36650 tensor(7.4459e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36660 tensor(7.3925e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36670 tensor(7.3613e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36680 tensor(7.2489e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36690 tensor(7.2785e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36700 tensor(7.0694e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36710 tensor(7.2374e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36720 tensor(6.8320e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36730 tensor(7.2558e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36740 tensor(6.6366e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36750 tensor(7.1692e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36760 tensor(6.5567e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36770 tensor(7.0741e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36780 tensor(6.4645e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36790 tensor(6.9911e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36800 tensor(6.3947e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36810 tensor(6.9112e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36820 tensor(6.3289e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36830 tensor(6.8403e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36840 tensor(6.2709e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36850 tensor(6.7756e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36860 tensor(6.2173e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36870 tensor(6.7171e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36880 tensor(6.1682e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36890 tensor(6.6638e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36900 tensor(6.1226e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36910 tensor(6.6150e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36920 tensor(6.0804e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36930 tensor(6.5703e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36940 tensor(6.0410e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36950 tensor(6.5291e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36960 tensor(6.0042e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36970 tensor(6.4910e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36980 tensor(5.9697e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
36990 tensor(6.4558e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37000 tensor(5.9374e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37010 tensor(6.4231e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37020 tensor(5.9071e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37030 tensor(6.3927e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37040 tensor(5.8785e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37050 tensor(6.3644e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37060 tensor(5.8515e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37070 tensor(6.3391e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37080 tensor(5.7157e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37090 tensor(6.2634e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37100 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
37110 tensor(8.8879e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37120 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
37130 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
37140 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
37150 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
37160 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
37170 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
37180 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
37190 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
37200 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
37210 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
37220 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
37230 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
37240 tensor(5.4627e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37250 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
37260 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
37270 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
37280 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
37290 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
37300 tensor(7.8810e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37310 tensor(7.9132e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37320 tensor(8.9678e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37330 tensor(8.6753e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37340 tensor(7.0458e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37350 tensor(8.4057e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37360 tensor(8.9104e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37370 tensor(9.0887e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37380 tensor(8.4109e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37390 tensor(8.3652e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37400 tensor(8.5522e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37410 tensor(8.4774e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37420 tensor(8.3136e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37430 tensor(8.3473e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37440 tensor(8.2730e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37450 tensor(8.2631e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37460 tensor(8.1785e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37470 tensor(8.1774e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37480 tensor(8.1025e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37490 tensor(8.1036e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37500 tensor(8.0267e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37510 tensor(8.0304e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37520 tensor(7.9583e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37530 tensor(7.9620e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37540 tensor(7.8936e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37550 tensor(7.8966e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37560 tensor(7.8331e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37570 tensor(7.8345e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37580 tensor(7.7767e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37590 tensor(7.7750e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37600 tensor(7.7243e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37610 tensor(7.7176e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37620 tensor(7.6762e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37630 tensor(7.6613e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37640 tensor(7.6327e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37650 tensor(7.6050e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37660 tensor(7.5939e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37670 tensor(7.5476e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37680 tensor(7.5594e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37690 tensor(7.4882e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37700 tensor(7.5277e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37710 tensor(7.4264e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37720 tensor(7.4966e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37730 tensor(7.3624e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37740 tensor(7.4635e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37750 tensor(7.2974e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37760 tensor(7.4252e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37770 tensor(7.2339e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37780 tensor(7.3784e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37790 tensor(7.1749e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37800 tensor(7.3212e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37810 tensor(7.1209e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37820 tensor(7.2555e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37830 tensor(7.0699e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37840 tensor(7.1859e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37850 tensor(7.0199e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37860 tensor(7.1159e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37870 tensor(6.9706e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37880 tensor(7.0469e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37890 tensor(6.9232e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37900 tensor(6.9779e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37910 tensor(6.8789e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37920 tensor(6.9068e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37930 tensor(6.8373e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37940 tensor(6.8324e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37950 tensor(6.7980e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37960 tensor(6.7545e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37970 tensor(6.7602e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37980 tensor(6.6756e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
37990 tensor(6.7204e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38000 tensor(6.5999e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38010 tensor(6.6761e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38020 tensor(6.5280e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38030 tensor(6.6297e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38040 tensor(6.4588e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38050 tensor(6.5823e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38060 tensor(6.3927e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38070 tensor(6.5341e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38080 tensor(6.3295e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38090 tensor(6.4858e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38100 tensor(6.2693e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38110 tensor(6.4379e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38120 tensor(6.2119e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38130 tensor(6.3907e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38140 tensor(6.1572e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38150 tensor(6.3444e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38160 tensor(6.1052e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38170 tensor(6.2993e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38180 tensor(6.0557e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38190 tensor(6.2555e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38200 tensor(6.0087e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38210 tensor(6.2131e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38220 tensor(5.9640e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38230 tensor(6.1722e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38240 tensor(5.9216e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38250 tensor(6.1328e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38260 tensor(5.8813e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38270 tensor(6.0950e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38280 tensor(5.8430e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38290 tensor(6.0588e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38300 tensor(5.8067e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38310 tensor(6.0241e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38320 tensor(5.7721e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38330 tensor(5.9909e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38340 tensor(5.7393e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38350 tensor(5.9592e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38360 tensor(5.7081e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38370 tensor(5.9290e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38380 tensor(5.6785e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38390 tensor(5.9001e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38400 tensor(5.6503e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38410 tensor(5.8726e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38420 tensor(5.6235e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38430 tensor(5.8464e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38440 tensor(5.5980e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38450 tensor(5.8214e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38460 tensor(5.5738e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38470 tensor(5.7977e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38480 tensor(5.5508e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38490 tensor(5.7750e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38500 tensor(5.5288e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38510 tensor(5.7535e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38520 tensor(5.5079e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38530 tensor(5.7330e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38540 tensor(5.4880e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38550 tensor(5.7136e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38560 tensor(5.4691e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38570 tensor(5.6950e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38580 tensor(5.4510e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38590 tensor(5.6774e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38600 tensor(5.4338e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38610 tensor(5.6607e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38620 tensor(5.4175e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38630 tensor(5.6448e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38640 tensor(5.4019e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38650 tensor(5.6297e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38660 tensor(5.3870e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38670 tensor(5.6153e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38680 tensor(5.3728e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38690 tensor(5.6017e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38700 tensor(5.3592e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38710 tensor(5.5889e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38720 tensor(5.3460e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38730 tensor(5.5793e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38740 tensor(5.3293e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38750 tensor(6.6607e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38760 tensor(1.6079e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38770 tensor(6.5005e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38780 tensor(7.8027e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38790 tensor(4.3878e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38800 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
38810 tensor(6.5423e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38820 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
38830 tensor(6.0651e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38840 tensor(8.7522e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38850 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
38860 tensor(4.4745e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38870 tensor(8.7139e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38880 tensor(8.6388e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38890 tensor(8.4759e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38900 tensor(7.8090e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38910 tensor(8.2454e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38920 tensor(7.2667e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38930 tensor(8.2106e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38940 tensor(7.1307e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38950 tensor(7.9580e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38960 tensor(7.0213e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38970 tensor(7.7881e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38980 tensor(6.9207e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
38990 tensor(7.6211e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39000 tensor(6.8436e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39010 tensor(7.4803e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39020 tensor(6.7738e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39030 tensor(7.3535e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39040 tensor(6.7157e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39050 tensor(7.2398e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39060 tensor(6.6668e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39070 tensor(7.1369e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39080 tensor(6.6264e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39090 tensor(7.0433e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39100 tensor(6.5937e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39110 tensor(6.9580e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39120 tensor(6.5677e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39130 tensor(6.8803e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39140 tensor(6.5476e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39150 tensor(6.8097e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39160 tensor(6.5324e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39170 tensor(6.7459e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39180 tensor(6.5210e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39190 tensor(6.6886e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39200 tensor(6.5127e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39210 tensor(6.6377e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39220 tensor(6.5063e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39230 tensor(6.5931e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39240 tensor(6.5012e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39250 tensor(6.5543e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39260 tensor(6.4967e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39270 tensor(6.5211e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39280 tensor(6.4923e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39290 tensor(6.4929e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39300 tensor(6.4876e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39310 tensor(6.4692e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39320 tensor(6.4826e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39330 tensor(6.4493e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39340 tensor(6.4771e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39350 tensor(6.4327e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39360 tensor(6.4712e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39370 tensor(6.4188e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39380 tensor(6.4649e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39390 tensor(6.4070e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39400 tensor(6.4583e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39410 tensor(6.3969e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39420 tensor(6.4515e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39430 tensor(6.3881e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39440 tensor(6.4445e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39450 tensor(6.3804e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39460 tensor(6.4376e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39470 tensor(6.3735e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39480 tensor(6.4307e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39490 tensor(6.3673e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39500 tensor(6.4240e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39510 tensor(6.3630e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39520 tensor(6.4646e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39530 tensor(5.8899e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39540 tensor(8.9407e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39550 tensor(9.4218e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39560 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
39570 tensor(9.7065e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39580 tensor(9.0363e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39590 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
39600 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
39610 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
39620 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
39630 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
39640 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
39650 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
39660 tensor(9.3859e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39670 tensor(9.6858e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39680 tensor(8.3062e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39690 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
39700 tensor(8.1712e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39710 tensor(9.6786e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39720 tensor(8.2415e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39730 tensor(9.4444e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39740 tensor(8.1561e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39750 tensor(9.2185e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39760 tensor(8.1323e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39770 tensor(9.0112e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39780 tensor(8.0874e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39790 tensor(8.8393e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39800 tensor(8.0456e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39810 tensor(8.6854e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39820 tensor(8.0027e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39830 tensor(8.5513e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39840 tensor(7.9597e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39850 tensor(8.4326e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39860 tensor(7.9175e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39870 tensor(8.3274e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39880 tensor(7.8761e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39890 tensor(8.2338e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39900 tensor(7.8360e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39910 tensor(8.1501e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39920 tensor(7.7972e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39930 tensor(8.0751e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39940 tensor(7.7600e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39950 tensor(8.0076e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39960 tensor(7.7242e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39970 tensor(7.9466e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39980 tensor(7.6899e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
39990 tensor(7.8913e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40000 tensor(7.6571e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40010 tensor(7.8409e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40020 tensor(7.6257e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40030 tensor(7.7948e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40040 tensor(7.5956e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40050 tensor(7.7525e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40060 tensor(7.5668e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40070 tensor(7.7133e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40080 tensor(7.5391e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40090 tensor(7.6770e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40100 tensor(7.5125e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40110 tensor(7.6431e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40120 tensor(7.4870e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40130 tensor(7.6113e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40140 tensor(7.4624e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40150 tensor(7.5813e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40160 tensor(7.4387e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40170 tensor(7.5528e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40180 tensor(7.4158e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40190 tensor(7.5257e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40200 tensor(7.3937e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40210 tensor(7.4997e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40220 tensor(7.3724e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40230 tensor(7.4747e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40240 tensor(7.3517e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40250 tensor(7.4504e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40260 tensor(7.3318e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40270 tensor(7.4266e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40280 tensor(7.3124e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40290 tensor(7.4031e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40300 tensor(7.2936e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40310 tensor(7.3796e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40320 tensor(7.2751e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40330 tensor(7.3558e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40340 tensor(7.2564e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40350 tensor(7.3310e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40360 tensor(7.2366e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40370 tensor(7.3047e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40380 tensor(7.2131e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40390 tensor(7.2759e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40400 tensor(7.1810e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40410 tensor(7.2424e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40420 tensor(7.1313e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40430 tensor(7.2008e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40440 tensor(7.0511e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40450 tensor(7.1525e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40460 tensor(6.9356e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40470 tensor(7.1221e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40480 tensor(6.7973e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40490 tensor(7.0870e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40500 tensor(6.7014e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40510 tensor(7.0078e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40520 tensor(6.6256e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40530 tensor(6.9351e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40540 tensor(6.5544e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40550 tensor(6.8638e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40560 tensor(6.4870e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40570 tensor(6.7969e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40580 tensor(6.4232e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40590 tensor(6.7338e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40600 tensor(6.3626e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40610 tensor(6.6744e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40620 tensor(6.3049e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40630 tensor(6.6186e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40640 tensor(6.2502e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40650 tensor(6.5661e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40660 tensor(6.1982e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40670 tensor(6.5169e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40680 tensor(6.1488e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40690 tensor(6.4706e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40700 tensor(6.1018e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40710 tensor(6.4271e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40720 tensor(6.0571e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40730 tensor(6.3862e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40740 tensor(6.0145e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40750 tensor(6.3477e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40760 tensor(5.9739e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40770 tensor(6.3116e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40780 tensor(5.9352e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40790 tensor(6.2775e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40800 tensor(5.8982e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40810 tensor(6.2455e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40820 tensor(5.8628e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40830 tensor(6.2153e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40840 tensor(5.8289e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40850 tensor(6.1868e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40860 tensor(5.7965e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40870 tensor(6.1599e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40880 tensor(5.7655e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40890 tensor(6.1345e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40900 tensor(5.7359e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40910 tensor(6.1105e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40920 tensor(5.7076e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40930 tensor(6.0878e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40940 tensor(5.6805e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40950 tensor(6.0662e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40960 tensor(5.6547e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40970 tensor(6.0457e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40980 tensor(5.6302e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
40990 tensor(6.0261e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41000 tensor(5.6067e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41010 tensor(6.0101e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41020 tensor(5.5788e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41030 tensor(9.1614e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41040 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
41050 tensor(7.5658e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41060 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
41070 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
41080 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
41090 tensor(4.8342e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41100 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
41110 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
41120 tensor(5.4084e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41130 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
41140 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
41150 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
41160 tensor(9.5749e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41170 tensor(8.7927e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41180 tensor(8.9139e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41190 tensor(8.1632e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41200 tensor(8.6032e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41210 tensor(8.6862e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41220 tensor(8.2064e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41230 tensor(8.0966e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41240 tensor(8.1104e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41250 tensor(8.0972e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41260 tensor(7.9709e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41270 tensor(7.9414e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41280 tensor(7.8769e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41290 tensor(7.8294e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41300 tensor(7.7707e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41310 tensor(7.7228e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41320 tensor(7.6791e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41330 tensor(7.6208e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41340 tensor(7.5916e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41350 tensor(7.5269e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41360 tensor(7.5096e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41370 tensor(7.4379e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41380 tensor(7.4328e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41390 tensor(7.3540e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41400 tensor(7.3604e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41410 tensor(7.2748e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41420 tensor(7.2921e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41430 tensor(7.2000e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41440 tensor(7.2275e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41450 tensor(7.1292e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41460 tensor(7.1661e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41470 tensor(7.0624e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41480 tensor(7.1074e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41490 tensor(6.9996e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41500 tensor(7.0509e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41510 tensor(6.9411e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41520 tensor(6.9955e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41530 tensor(6.8872e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41540 tensor(6.9401e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41550 tensor(6.8385e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41560 tensor(6.8836e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41570 tensor(6.7951e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41580 tensor(6.8251e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41590 tensor(6.7565e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41600 tensor(6.7641e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41610 tensor(6.7224e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41620 tensor(6.7008e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41630 tensor(6.6928e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41640 tensor(6.6366e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41650 tensor(6.6659e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41660 tensor(6.5752e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41670 tensor(6.6371e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41680 tensor(6.5206e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41690 tensor(6.6047e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41700 tensor(6.4719e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41710 tensor(6.5712e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41720 tensor(6.4264e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41730 tensor(6.5381e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41740 tensor(6.3835e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41750 tensor(6.5055e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41760 tensor(6.3432e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41770 tensor(6.4735e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41780 tensor(6.3050e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41790 tensor(6.4423e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41800 tensor(6.2688e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41810 tensor(6.4120e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41820 tensor(6.2344e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41830 tensor(6.3827e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41840 tensor(6.2016e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41850 tensor(6.3542e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41860 tensor(6.1704e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41870 tensor(6.3267e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41880 tensor(6.1407e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41890 tensor(6.3001e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41900 tensor(6.1123e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41910 tensor(6.2745e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41920 tensor(6.0849e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41930 tensor(6.2505e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41940 tensor(6.0331e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41950 tensor(7.7786e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41960 tensor(6.1333e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41970 tensor(6.8409e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
41980 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
41990 tensor(7.0608e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42000 tensor(9.3818e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42010 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
42020 tensor(3.1117e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42030 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
42040 tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
42050 tensor(9.8082e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42060 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
42070 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
42080 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
42090 tensor(8.4520e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42100 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
42110 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
42120 tensor(4.8723e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42130 tensor(8.9081e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42140 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
42150 tensor(5.7625e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42160 tensor(3.8971e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42170 tensor(7.6960e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42180 tensor(5.0969e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42190 tensor(8.3498e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42200 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
42210 tensor(9.6109e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42220 tensor(8.0874e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42230 tensor(9.3694e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42240 tensor(8.8567e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42250 tensor(8.8989e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42260 tensor(8.5107e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42270 tensor(8.8816e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42280 tensor(8.4502e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42290 tensor(8.6647e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42300 tensor(8.3411e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42310 tensor(8.5511e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42320 tensor(8.2483e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42330 tensor(8.4197e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42340 tensor(8.1584e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42350 tensor(8.3112e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42360 tensor(8.0752e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42370 tensor(8.2080e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42380 tensor(7.9962e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42390 tensor(8.1148e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42400 tensor(7.9219e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42410 tensor(8.0283e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42420 tensor(7.8517e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42430 tensor(7.9484e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42440 tensor(7.7855e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42450 tensor(7.8740e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42460 tensor(7.7228e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42470 tensor(7.8048e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42480 tensor(7.6636e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42490 tensor(7.7400e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42500 tensor(7.6076e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42510 tensor(7.6794e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42520 tensor(7.5547e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42530 tensor(7.6224e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42540 tensor(7.5047e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42550 tensor(7.5686e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42560 tensor(7.4577e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42570 tensor(7.5176e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42580 tensor(7.4137e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42590 tensor(7.4689e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42600 tensor(7.3727e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42610 tensor(7.4219e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42620 tensor(7.3351e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42630 tensor(7.3759e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42640 tensor(7.3009e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42650 tensor(7.3301e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42660 tensor(7.2706e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42670 tensor(7.2836e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42680 tensor(7.2439e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42690 tensor(7.2356e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42700 tensor(7.2207e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42710 tensor(7.1855e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42720 tensor(7.1999e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42730 tensor(7.1329e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42740 tensor(7.1791e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42750 tensor(7.0784e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42760 tensor(7.1545e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42770 tensor(7.0232e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42780 tensor(7.1202e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42790 tensor(6.9673e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42800 tensor(7.0712e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42810 tensor(6.9054e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42820 tensor(7.0078e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42830 tensor(6.8290e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42840 tensor(6.9445e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42850 tensor(6.7377e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42860 tensor(6.9091e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42870 tensor(6.6396e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42880 tensor(6.8735e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42890 tensor(6.5690e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42900 tensor(6.8161e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42910 tensor(6.4999e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42920 tensor(6.7624e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42930 tensor(6.4382e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42940 tensor(6.7065e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42950 tensor(6.3783e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42960 tensor(6.6519e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42970 tensor(6.3208e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42980 tensor(6.5984e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
42990 tensor(6.2657e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43000 tensor(6.5466e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43010 tensor(6.2129e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43020 tensor(6.4967e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43030 tensor(6.1625e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43040 tensor(6.4489e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43050 tensor(6.1142e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43060 tensor(6.4032e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43070 tensor(6.0682e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43080 tensor(6.3596e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43090 tensor(6.0242e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43100 tensor(6.3182e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43110 tensor(5.9823e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43120 tensor(6.2788e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43130 tensor(5.9424e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43140 tensor(6.2415e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43150 tensor(5.9043e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43160 tensor(6.2061e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43170 tensor(5.8679e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43180 tensor(6.1727e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43190 tensor(5.8332e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43200 tensor(6.1410e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43210 tensor(5.8001e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43220 tensor(6.1110e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43230 tensor(5.7685e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43240 tensor(6.0826e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43250 tensor(5.7383e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43260 tensor(6.0557e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43270 tensor(5.7094e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43280 tensor(6.0303e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43290 tensor(5.6818e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43300 tensor(6.0062e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43310 tensor(5.6553e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43320 tensor(5.9834e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43330 tensor(5.6301e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43340 tensor(5.9618e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43350 tensor(5.6059e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43360 tensor(5.9413e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43370 tensor(5.5827e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43380 tensor(5.9219e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43390 tensor(5.5606e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43400 tensor(5.9035e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43410 tensor(5.5394e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43420 tensor(5.8861e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43430 tensor(5.5190e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43440 tensor(5.8695e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43450 tensor(5.4996e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43460 tensor(5.8537e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43470 tensor(5.4810e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43480 tensor(5.8391e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43490 tensor(5.4665e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43500 tensor(6.8745e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43510 tensor(7.9396e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43520 tensor(9.9859e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43530 tensor(9.7535e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43540 tensor(6.6746e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43550 tensor(6.7451e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43560 tensor(9.0977e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43570 tensor(8.8198e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43580 tensor(9.1031e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43590 tensor(8.5525e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43600 tensor(8.6911e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43610 tensor(8.3201e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43620 tensor(8.4714e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43630 tensor(8.1695e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43640 tensor(8.3229e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43650 tensor(8.0525e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43660 tensor(8.2049e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43670 tensor(7.9512e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43680 tensor(8.1007e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43690 tensor(7.8567e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43700 tensor(8.0004e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43710 tensor(7.7654e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43720 tensor(7.8980e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43730 tensor(7.6778e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43740 tensor(7.7893e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43750 tensor(7.5943e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43760 tensor(7.6686e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43770 tensor(7.5150e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43780 tensor(7.5312e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43790 tensor(7.4450e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43800 tensor(7.3741e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43810 tensor(7.3884e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43820 tensor(7.2093e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43830 tensor(7.3217e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43840 tensor(7.0758e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43850 tensor(7.2291e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43860 tensor(6.9710e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43870 tensor(7.1313e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43880 tensor(6.8866e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43890 tensor(7.0296e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43900 tensor(6.8179e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43910 tensor(6.9291e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43920 tensor(6.7564e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43930 tensor(6.8311e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43940 tensor(6.6902e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43950 tensor(6.7337e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43960 tensor(6.6045e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43970 tensor(6.6342e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43980 tensor(6.4883e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
43990 tensor(6.5722e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44000 tensor(6.3343e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44010 tensor(6.6134e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44020 tensor(6.1743e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44030 tensor(6.5454e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44040 tensor(6.1307e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44050 tensor(6.4737e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44060 tensor(6.0689e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44070 tensor(6.4027e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44080 tensor(6.0171e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44090 tensor(6.3394e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44100 tensor(5.9686e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44110 tensor(6.2792e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44120 tensor(5.9228e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44130 tensor(6.2231e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44140 tensor(5.8799e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44150 tensor(6.1710e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44160 tensor(5.8393e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44170 tensor(6.1225e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44180 tensor(5.8009e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44190 tensor(6.0775e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44200 tensor(5.7649e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44210 tensor(6.0358e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44220 tensor(5.7309e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44230 tensor(5.9970e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44240 tensor(5.6991e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44250 tensor(5.9609e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44260 tensor(5.6691e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44270 tensor(5.9270e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44280 tensor(5.6409e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44290 tensor(5.8952e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44300 tensor(5.6143e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44310 tensor(5.8654e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44320 tensor(5.5893e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44330 tensor(5.8372e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44340 tensor(5.5656e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44350 tensor(5.8106e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44360 tensor(5.5433e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44370 tensor(5.7855e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44380 tensor(5.5221e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44390 tensor(5.7617e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44400 tensor(5.5020e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44410 tensor(5.7392e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44420 tensor(5.4830e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44430 tensor(5.7179e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44440 tensor(5.4649e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44450 tensor(5.6977e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44460 tensor(5.4477e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44470 tensor(5.6785e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44480 tensor(5.4314e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44490 tensor(5.6603e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44500 tensor(5.4159e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44510 tensor(5.6431e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44520 tensor(5.4011e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44530 tensor(5.6266e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44540 tensor(5.3869e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44550 tensor(5.6110e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44560 tensor(5.3734e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44570 tensor(5.5966e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44580 tensor(5.3604e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44590 tensor(5.9067e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44600 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
44610 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
44620 tensor(8.4416e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44630 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
44640 tensor(6.8912e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44650 tensor(8.0518e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44660 tensor(5.7608e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44670 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
44680 tensor(9.9620e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44690 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
44700 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
44710 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
44720 tensor(9.9086e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44730 tensor(7.3980e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44740 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
44750 tensor(7.5310e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44760 tensor(9.3067e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44770 tensor(8.7021e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44780 tensor(8.8956e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44790 tensor(9.0743e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44800 tensor(8.6922e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44810 tensor(8.5211e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44820 tensor(8.6326e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44830 tensor(8.4180e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44840 tensor(8.4069e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44850 tensor(8.3378e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44860 tensor(8.2704e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44870 tensor(8.2225e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44880 tensor(8.1525e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44890 tensor(8.1226e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44900 tensor(8.0447e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44910 tensor(8.0332e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44920 tensor(7.9460e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44930 tensor(7.9516e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44940 tensor(7.8573e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44950 tensor(7.8748e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44960 tensor(7.7775e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44970 tensor(7.8024e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44980 tensor(7.7052e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
44990 tensor(7.7335e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45000 tensor(7.6395e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45010 tensor(7.6675e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45020 tensor(7.5793e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45030 tensor(7.6033e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45040 tensor(7.5234e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45050 tensor(7.5394e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45060 tensor(7.4698e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45070 tensor(7.4730e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45080 tensor(7.4150e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45090 tensor(7.3988e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45100 tensor(7.3532e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45110 tensor(7.3053e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45120 tensor(7.2768e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45130 tensor(7.1746e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45140 tensor(7.2017e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45150 tensor(6.9903e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45160 tensor(7.2167e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45170 tensor(6.7454e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45180 tensor(7.1646e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45190 tensor(6.7384e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45200 tensor(6.9853e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45210 tensor(6.7126e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45220 tensor(6.8604e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45230 tensor(6.6872e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45240 tensor(6.7710e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45250 tensor(6.6506e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45260 tensor(6.6996e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45270 tensor(6.6081e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45280 tensor(6.6355e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45290 tensor(6.5579e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45300 tensor(6.5676e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45310 tensor(6.4880e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45320 tensor(6.4760e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45330 tensor(6.3670e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45340 tensor(6.3442e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45350 tensor(6.2205e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45360 tensor(6.3403e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45370 tensor(6.0468e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45380 tensor(6.4692e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45390 tensor(5.9000e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45400 tensor(6.3746e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45410 tensor(5.8547e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45420 tensor(6.3159e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45430 tensor(5.8073e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45440 tensor(6.2519e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45450 tensor(5.7580e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45460 tensor(6.1959e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45470 tensor(5.7157e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45480 tensor(6.1422e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45490 tensor(5.6736e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45500 tensor(6.0941e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45510 tensor(5.6343e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45520 tensor(6.0494e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45530 tensor(5.5967e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45540 tensor(6.0086e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45550 tensor(5.5611e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45560 tensor(5.9708e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45570 tensor(5.5274e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45580 tensor(5.9359e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45590 tensor(5.4955e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45600 tensor(5.9034e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45610 tensor(5.4654e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45620 tensor(5.8732e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45630 tensor(5.4370e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45640 tensor(5.8449e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45650 tensor(5.4101e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45660 tensor(5.8184e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45670 tensor(5.3847e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45680 tensor(5.7936e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45690 tensor(5.3607e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45700 tensor(5.7702e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45710 tensor(5.3379e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45720 tensor(5.7482e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45730 tensor(5.3164e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45740 tensor(5.7274e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45750 tensor(5.2959e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45760 tensor(5.7095e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45770 tensor(5.3568e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45780 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
45790 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
45800 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
45810 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
45820 tensor(7.5047e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45830 tensor(7.6121e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45840 tensor(5.9810e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45850 tensor(8.0460e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45860 tensor(9.2806e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45870 tensor(9.0703e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45880 tensor(8.1421e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45890 tensor(8.6258e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45900 tensor(8.3130e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45910 tensor(8.4161e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45920 tensor(8.1525e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45930 tensor(8.2274e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45940 tensor(8.0860e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45950 tensor(8.0776e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45960 tensor(7.9764e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45970 tensor(7.9513e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45980 tensor(7.8898e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
45990 tensor(7.8346e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46000 tensor(7.8027e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46010 tensor(7.7322e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46020 tensor(7.7202e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46030 tensor(7.6411e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46040 tensor(7.6387e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46050 tensor(7.5603e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46060 tensor(7.5572e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46070 tensor(7.4892e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46080 tensor(7.4737e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46090 tensor(7.4263e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46100 tensor(7.3859e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46110 tensor(7.3697e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46120 tensor(7.2919e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46130 tensor(7.3173e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46140 tensor(7.1898e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46150 tensor(7.2705e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46160 tensor(7.0810e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46170 tensor(7.2324e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46180 tensor(6.9793e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46190 tensor(7.1832e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46200 tensor(6.9144e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46210 tensor(7.1127e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46220 tensor(6.8713e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46230 tensor(7.0466e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46240 tensor(6.8359e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46250 tensor(6.9861e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46260 tensor(6.8067e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46270 tensor(6.9311e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46280 tensor(6.7813e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46290 tensor(6.8813e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46300 tensor(6.7573e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46310 tensor(6.8356e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46320 tensor(6.7324e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46330 tensor(6.7920e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46340 tensor(6.7036e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46350 tensor(6.7467e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46360 tensor(6.6654e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46370 tensor(6.6926e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46380 tensor(6.6056e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46390 tensor(6.6156e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46400 tensor(6.5027e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46410 tensor(6.5095e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46420 tensor(6.3763e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46430 tensor(6.4679e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46440 tensor(6.2421e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46450 tensor(6.4712e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46460 tensor(6.1444e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46470 tensor(6.4028e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46480 tensor(6.0769e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46490 tensor(6.3423e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46500 tensor(6.0144e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46510 tensor(6.2897e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46520 tensor(5.9548e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46530 tensor(6.2376e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46540 tensor(5.8983e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46550 tensor(6.1891e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46560 tensor(5.8456e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46570 tensor(6.1425e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46580 tensor(5.7959e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46590 tensor(6.0981e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46600 tensor(5.7496e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46610 tensor(6.0559e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46620 tensor(5.7067e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46630 tensor(6.0154e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46640 tensor(5.6673e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46650 tensor(5.9766e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46660 tensor(5.6310e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46670 tensor(5.9396e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46680 tensor(5.5972e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46690 tensor(5.9044e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46700 tensor(5.5656e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46710 tensor(5.8711e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46720 tensor(5.5359e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46730 tensor(5.8395e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46740 tensor(5.5079e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46750 tensor(5.8096e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46760 tensor(5.4814e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46770 tensor(5.7814e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46780 tensor(5.4563e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46790 tensor(5.7547e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46800 tensor(5.4324e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46810 tensor(5.7294e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46820 tensor(5.4097e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46830 tensor(5.7421e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46840 tensor(4.1111e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46850 tensor(9.9579e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46860 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
46870 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
46880 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
46890 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
46900 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
46910 tensor(8.9365e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46920 tensor(7.4554e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46930 tensor(7.6579e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46940 tensor(9.0855e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46950 tensor(7.6831e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46960 tensor(8.1634e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46970 tensor(7.6915e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46980 tensor(8.1521e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
46990 tensor(7.5779e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47000 tensor(7.8974e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47010 tensor(7.5329e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47020 tensor(7.7580e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47030 tensor(7.4826e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47040 tensor(7.6150e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47050 tensor(7.4173e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47060 tensor(7.4858e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47070 tensor(7.3408e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47080 tensor(7.3533e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47090 tensor(7.2442e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47100 tensor(7.1990e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47110 tensor(7.1416e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47120 tensor(7.0264e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47130 tensor(7.1118e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47140 tensor(6.7984e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47150 tensor(7.1189e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47160 tensor(6.6915e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47170 tensor(6.9453e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47180 tensor(6.6529e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47190 tensor(6.8258e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47200 tensor(6.6061e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47210 tensor(6.7064e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47220 tensor(6.5385e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47230 tensor(6.5963e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47240 tensor(6.4429e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47250 tensor(6.5005e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47260 tensor(6.3192e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47270 tensor(6.4904e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47280 tensor(6.1369e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47290 tensor(6.5406e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47300 tensor(6.0317e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47310 tensor(6.4448e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47320 tensor(5.9917e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47330 tensor(6.3786e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47340 tensor(5.9420e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47350 tensor(6.3102e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47360 tensor(5.8949e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47370 tensor(6.2501e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47380 tensor(5.8518e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47390 tensor(6.1932e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47400 tensor(5.8108e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47410 tensor(6.1410e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47420 tensor(5.7728e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47430 tensor(6.0927e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47440 tensor(5.7373e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47450 tensor(6.0479e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47460 tensor(5.7041e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47470 tensor(6.0065e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47480 tensor(5.6730e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47490 tensor(5.9680e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47500 tensor(5.6437e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47510 tensor(5.9320e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47520 tensor(5.6160e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47530 tensor(5.8985e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47540 tensor(5.5898e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47550 tensor(5.8670e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47560 tensor(5.5650e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47570 tensor(5.8374e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47580 tensor(5.5415e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47590 tensor(5.8096e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47600 tensor(5.5192e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47610 tensor(5.7834e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47620 tensor(5.4980e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47630 tensor(5.7587e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47640 tensor(5.4779e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47650 tensor(5.7353e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47660 tensor(5.4587e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47670 tensor(5.7132e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47680 tensor(5.4405e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47690 tensor(5.6923e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47700 tensor(5.4232e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47710 tensor(5.6725e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47720 tensor(5.4067e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47730 tensor(5.6537e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47740 tensor(5.3910e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47750 tensor(5.6359e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47760 tensor(5.3760e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47770 tensor(5.6189e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47780 tensor(5.3617e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47790 tensor(5.6028e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47800 tensor(5.3481e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47810 tensor(5.5874e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47820 tensor(5.3350e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47830 tensor(5.5728e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47840 tensor(5.3226e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47850 tensor(5.5589e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47860 tensor(5.3107e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47870 tensor(5.5456e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47880 tensor(5.2993e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47890 tensor(5.5331e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47900 tensor(5.2895e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47910 tensor(5.9535e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47920 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
47930 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
47940 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
47950 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
47960 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
47970 tensor(9.3512e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
47980 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
47990 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
48000 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
48010 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
48020 tensor(8.6776e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48030 tensor(6.8954e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48040 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
48050 tensor(9.8657e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48060 tensor(5.2347e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48070 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
48080 tensor(6.3463e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48090 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
48100 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
48110 tensor(5.0603e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48120 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
48130 tensor(3.9342e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48140 tensor(6.2008e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48150 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
48160 tensor(7.6694e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48170 tensor(7.4016e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48180 tensor(9.9876e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48190 tensor(8.5255e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48200 tensor(7.3468e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48210 tensor(8.3346e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48220 tensor(8.1378e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48230 tensor(7.9694e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48240 tensor(7.7905e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48250 tensor(8.0271e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48260 tensor(7.7319e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48270 tensor(7.8746e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48280 tensor(7.6416e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48290 tensor(7.8118e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48300 tensor(7.5571e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48310 tensor(7.7280e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48320 tensor(7.4834e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48330 tensor(7.6586e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48340 tensor(7.4137e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48350 tensor(7.5902e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48360 tensor(7.3519e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48370 tensor(7.5251e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48380 tensor(7.2965e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48390 tensor(7.4611e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48400 tensor(7.2478e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48410 tensor(7.3973e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48420 tensor(7.2050e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48430 tensor(7.3324e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48440 tensor(7.1666e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48450 tensor(7.2655e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48460 tensor(7.1297e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48470 tensor(7.1947e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48480 tensor(7.0902e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48490 tensor(7.1161e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48500 tensor(7.0444e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48510 tensor(7.0243e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48520 tensor(6.9967e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48530 tensor(6.9156e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48540 tensor(6.9713e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48550 tensor(6.7901e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48560 tensor(6.9620e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48570 tensor(6.7144e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48580 tensor(6.8760e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48590 tensor(6.7013e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48600 tensor(6.8030e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48610 tensor(6.6806e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48620 tensor(6.7458e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48630 tensor(6.6610e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48640 tensor(6.7020e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48650 tensor(6.6438e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48660 tensor(6.6672e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48670 tensor(6.6295e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48680 tensor(6.6387e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48690 tensor(6.6179e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48700 tensor(6.6146e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48710 tensor(6.6082e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48720 tensor(6.5937e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48730 tensor(6.5998e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48740 tensor(6.5751e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48750 tensor(6.5920e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48760 tensor(6.5579e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48770 tensor(6.5843e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48780 tensor(6.5419e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48790 tensor(6.5764e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48800 tensor(6.5265e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48810 tensor(6.5683e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48820 tensor(6.5117e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48830 tensor(6.5599e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48840 tensor(6.4975e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48850 tensor(6.5511e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48860 tensor(6.4837e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48870 tensor(6.5421e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48880 tensor(6.4704e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48890 tensor(6.5329e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48900 tensor(6.4576e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48910 tensor(6.5234e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48920 tensor(6.4453e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48930 tensor(6.5138e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48940 tensor(6.4336e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48950 tensor(6.5038e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48960 tensor(6.4223e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48970 tensor(6.4936e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48980 tensor(6.4114e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
48990 tensor(6.4830e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49000 tensor(6.4011e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49010 tensor(6.4719e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49020 tensor(6.3913e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49030 tensor(6.4600e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49040 tensor(6.3821e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49050 tensor(6.4470e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49060 tensor(6.3738e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49070 tensor(6.4323e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49080 tensor(6.3663e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49090 tensor(6.4154e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49100 tensor(6.3599e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49110 tensor(6.3954e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49120 tensor(6.3547e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49130 tensor(6.3712e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49140 tensor(6.3507e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49150 tensor(6.3414e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49160 tensor(6.3479e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49170 tensor(6.3047e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49180 tensor(6.3465e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49190 tensor(6.2593e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49200 tensor(6.3473e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49210 tensor(6.2040e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49220 tensor(6.3507e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49230 tensor(6.1396e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49240 tensor(6.3544e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49250 tensor(6.0717e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49260 tensor(6.3523e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49270 tensor(6.0083e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49280 tensor(6.3401e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49290 tensor(5.9520e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49300 tensor(6.3203e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49310 tensor(5.9009e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49320 tensor(6.2958e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49330 tensor(5.8543e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49340 tensor(6.2682e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49350 tensor(5.8112e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49360 tensor(6.2392e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49370 tensor(5.7709e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49380 tensor(6.2096e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49390 tensor(5.7332e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49400 tensor(6.1799e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49410 tensor(5.6977e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49420 tensor(6.1507e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49430 tensor(5.6641e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49440 tensor(6.1221e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49450 tensor(5.6323e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49460 tensor(6.0944e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49470 tensor(5.6020e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49480 tensor(6.0677e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49490 tensor(5.5733e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49500 tensor(6.0420e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49510 tensor(5.5459e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49520 tensor(6.0173e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49530 tensor(5.5198e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49540 tensor(5.9937e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49550 tensor(5.4949e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49560 tensor(5.9712e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49570 tensor(5.4712e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49580 tensor(5.9497e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49590 tensor(5.4485e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49600 tensor(5.9292e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49610 tensor(5.4267e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49620 tensor(5.9097e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49630 tensor(5.4060e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49640 tensor(5.8912e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49650 tensor(5.3861e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49660 tensor(5.8736e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49670 tensor(5.3670e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49680 tensor(5.8568e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49690 tensor(5.3487e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49700 tensor(5.8409e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49710 tensor(5.3312e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49720 tensor(5.8259e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49730 tensor(5.3142e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49740 tensor(5.8128e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49750 tensor(5.2913e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49760 tensor(6.0943e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49770 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
49780 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
49790 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
49800 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
49810 tensor(6.1244e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49820 tensor(7.7813e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49830 tensor(5.9179e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49840 tensor(5.0729e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49850 tensor(8.5716e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49860 tensor(5.2269e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49870 tensor(7.5326e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49880 tensor(4.9415e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49890 tensor(9.9189e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49900 tensor(7.2095e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49910 tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
49920 tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)
49930 tensor(6.8168e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49940 tensor(9.4801e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49950 tensor(9.0681e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49960 tensor(8.9719e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49970 tensor(8.0228e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49980 tensor(8.0152e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
49990 tensor(7.9789e-05, device='cuda:0', dtype=torch.float64,
       grad_fn=<NormBackward1>)
Result - Target = tensor([[[[ 1.3989e-05,  9.3296e-06,  1.0238e-05,  7.5342e-06],
          [ 9.3296e-06,  4.7734e-06,  5.9079e-06,  3.8970e-06],
          [ 1.0238e-05,  5.7855e-06,  6.1793e-06,  3.9344e-06],
          [ 7.5342e-06,  4.2908e-06,  3.9793e-06,  1.6228e-06]],

         [[ 9.3296e-06,  5.7169e-06,  6.0681e-06,  3.1167e-06],
          [ 4.7734e-06,  4.2811e-07,  1.6436e-06, -7.4528e-07],
          [ 5.9079e-06,  1.8404e-06,  2.9367e-06,  1.6871e-08],
          [ 3.8970e-06,  4.8202e-07,  5.4506e-07, -3.5104e-06]],

         [[ 1.0238e-05,  6.0681e-06,  6.9270e-06,  4.5318e-06],
          [ 5.7855e-06,  1.2934e-06,  2.3071e-06, -1.7644e-07],
          [ 6.1793e-06,  2.0651e-06,  2.6802e-06,  4.4679e-08],
          [ 3.9344e-06, -6.8087e-08,  6.6931e-07, -1.5845e-06]],

         [[ 7.5342e-06,  3.1167e-06,  4.5318e-06,  2.6768e-06],
          [ 4.2908e-06, -6.6282e-07,  2.2896e-07, -1.8526e-06],
          [ 3.9793e-06, -2.4347e-07,  1.1784e-06, -8.8750e-07],
          [ 1.6228e-06, -1.8529e-06, -1.0182e-06, -4.4768e-06]]],


        [[[ 9.3296e-06,  4.7734e-06,  5.7855e-06,  4.2908e-06],
          [ 5.7169e-06,  4.2811e-07,  1.8404e-06,  4.8202e-07],
          [ 6.0681e-06,  1.2934e-06,  2.0651e-06, -6.8087e-08],
          [ 3.1167e-06, -6.6282e-07, -2.4347e-07, -1.8529e-06]],

         [[ 4.7734e-06,  4.2811e-07,  1.2934e-06, -6.6282e-07],
          [ 4.2811e-07, -5.1079e-06, -3.4739e-06, -4.9201e-06],
          [ 1.6436e-06, -3.4739e-06, -1.6639e-06, -4.5232e-06],
          [-7.4528e-07, -4.9201e-06, -4.1224e-06, -6.6639e-06]],

         [[ 5.9079e-06,  1.6436e-06,  2.3071e-06,  2.2896e-07],
          [ 1.8404e-06, -3.4739e-06, -2.4990e-06, -5.0984e-06],
          [ 2.9367e-06, -1.6639e-06, -9.2789e-07, -4.2039e-06],
          [ 1.6871e-08, -4.5232e-06, -3.4974e-06, -5.6036e-06]],

         [[ 3.8970e-06, -7.4528e-07, -1.7644e-07, -1.8526e-06],
          [ 4.8202e-07, -4.9201e-06, -5.0984e-06, -6.2299e-06],
          [ 5.4506e-07, -4.1224e-06, -3.4532e-06, -6.0955e-06],
          [-3.5104e-06, -6.6639e-06, -6.8980e-06, -8.4502e-06]]],


        [[[ 1.0238e-05,  5.9079e-06,  6.1793e-06,  3.9793e-06],
          [ 6.0681e-06,  1.6436e-06,  2.9367e-06,  5.4506e-07],
          [ 6.9270e-06,  2.3071e-06,  2.6802e-06,  6.6931e-07],
          [ 4.5318e-06,  2.2896e-07,  1.1784e-06, -1.0182e-06]],

         [[ 5.7855e-06,  1.8404e-06,  2.0651e-06, -2.4347e-07],
          [ 1.2934e-06, -3.4739e-06, -1.6639e-06, -4.1224e-06],
          [ 2.3071e-06, -2.4990e-06, -9.2789e-07, -3.4974e-06],
          [-1.7644e-07, -5.0984e-06, -3.4532e-06, -6.8980e-06]],

         [[ 6.1793e-06,  2.9367e-06,  2.6802e-06,  1.1784e-06],
          [ 2.0651e-06, -1.6639e-06, -9.2789e-07, -3.4532e-06],
          [ 2.6802e-06, -9.2789e-07, -7.0614e-07, -2.7258e-06],
          [ 4.4679e-08, -4.2039e-06, -2.7258e-06, -4.3460e-06]],

         [[ 3.9344e-06,  1.6871e-08,  4.4679e-08, -8.8750e-07],
          [-6.8087e-08, -4.5232e-06, -4.2039e-06, -6.0955e-06],
          [ 6.6931e-07, -3.4974e-06, -2.7258e-06, -4.1425e-06],
          [-1.5845e-06, -5.6036e-06, -4.3460e-06, -6.9111e-06]]],


        [[[ 7.5342e-06,  3.8970e-06,  3.9344e-06,  1.6228e-06],
          [ 3.1167e-06, -7.4528e-07,  1.6871e-08, -3.5104e-06],
          [ 4.5318e-06, -1.7644e-07,  4.4679e-08, -1.5845e-06],
          [ 2.6768e-06, -1.8526e-06, -8.8750e-07, -4.4768e-06]],

         [[ 4.2908e-06,  4.8202e-07, -6.8087e-08, -1.8529e-06],
          [-6.6282e-07, -4.9201e-06, -4.5232e-06, -6.6639e-06],
          [ 2.2896e-07, -5.0984e-06, -4.2039e-06, -5.6036e-06],
          [-1.8526e-06, -6.2299e-06, -6.0955e-06, -8.4502e-06]],

         [[ 3.9793e-06,  5.4506e-07,  6.6931e-07, -1.0182e-06],
          [-2.4347e-07, -4.1224e-06, -3.4974e-06, -6.8980e-06],
          [ 1.1784e-06, -3.4532e-06, -2.7258e-06, -4.3460e-06],
          [-8.8750e-07, -6.0955e-06, -4.1425e-06, -6.9111e-06]],

         [[ 1.6228e-06, -3.5104e-06, -1.5845e-06, -4.4768e-06],
          [-1.8529e-06, -6.6639e-06, -5.6036e-06, -8.4502e-06],
          [-1.0182e-06, -6.8980e-06, -4.3460e-06, -6.9111e-06],
          [-4.4768e-06, -8.4502e-06, -6.9111e-06, -8.6382e-06]]]],
       device='cuda:0', dtype=torch.float64, grad_fn=<SubBackward0>)
Equivalent v =  tensor(-0.0036, device='cuda:0', dtype=torch.float64, grad_fn=<RsubBackward1>)
M1 =  tensor([[ 0.2407,  0.0068,  0.0271, -0.0040,  0.0076,  0.0154, -0.0168, -0.0125],
        [ 0.0068,  0.2476,  0.0100, -0.0060,  0.0081,  0.0117,  0.0464, -0.0088],
        [ 0.0271,  0.0100,  0.2375, -0.0063,  0.0215,  0.0268, -0.0253, -0.0149],
        [-0.0040, -0.0060, -0.0063,  0.2399, -0.0057, -0.0154, -0.0354,  0.0199],
        [ 0.0076,  0.0081,  0.0215, -0.0057,  0.2584,  0.0178, -0.0252, -0.0112],
        [ 0.0154,  0.0117,  0.0268, -0.0154,  0.0178,  0.2702,  0.0144, -0.0080],
        [-0.0168,  0.0464, -0.0253, -0.0354, -0.0252,  0.0144,  0.2893, -0.0050],
        [-0.0125, -0.0088, -0.0149,  0.0199, -0.0112, -0.0080, -0.0050,  0.2382]],
       device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)
M2 =  tensor([[ 0.1777, -0.0621,  0.0074,  0.0443,  0.0131,  0.0564,  0.0314, -0.0380],
        [-0.0621,  0.2385, -0.0074,  0.0080, -0.0169,  0.0392,  0.0372, -0.0298],
        [ 0.0074, -0.0074,  0.2503,  0.0055,  0.0104, -0.0077,  0.0045,  0.0036],
        [ 0.0443,  0.0080,  0.0055,  0.2354,  0.0105, -0.0228, -0.0236,  0.0180],
        [ 0.0131, -0.0169,  0.0104,  0.0105,  0.2603, -0.0031, -0.0056,  0.0012],
        [ 0.0564,  0.0392, -0.0077, -0.0228, -0.0031,  0.2382, -0.0490,  0.0053],
        [ 0.0314,  0.0372,  0.0045, -0.0236, -0.0056, -0.0490,  0.2521,  0.0310],
        [-0.0380, -0.0298,  0.0036,  0.0180,  0.0012,  0.0053,  0.0310,  0.2397]],
       device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)
M3 =  tensor([[ 0.3436,  0.0302, -0.0494, -0.0175, -0.0605, -0.0193,  0.0288,  0.0113],
        [ 0.0302,  0.2383,  0.0017,  0.0025, -0.0077, -0.0250,  0.0257,  0.0237],
        [-0.0494,  0.0017,  0.2740,  0.0053,  0.0255,  0.0228, -0.0235, -0.0209],
        [-0.0175,  0.0025,  0.0053,  0.2600,  0.0097,  0.0080, -0.0084, -0.0059],
        [-0.0605, -0.0077,  0.0255,  0.0097,  0.2937,  0.0218, -0.0258, -0.0150],
        [-0.0193, -0.0250,  0.0228,  0.0080,  0.0218,  0.2533,  0.0016,  0.0071],
        [ 0.0288,  0.0257, -0.0235, -0.0084, -0.0258,  0.0016,  0.2588, -0.0063],
        [ 0.0113,  0.0237, -0.0209, -0.0059, -0.0150,  0.0071, -0.0063,  0.2462]],
       device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)
M4 =  tensor([[ 0.2381,  0.0252,  0.0149, -0.0228,  0.0398, -0.0526, -0.0435,  0.0392],
        [ 0.0252,  0.2756, -0.0042, -0.0046,  0.0165, -0.0259, -0.1093,  0.0150],
        [ 0.0149, -0.0042,  0.2382, -0.0044, -0.0573, -0.0420,  0.0443,  0.0322],
        [-0.0228, -0.0046, -0.0044,  0.2646, -0.0144,  0.0302,  0.0674, -0.0320],
        [ 0.0398,  0.0165, -0.0573, -0.0144,  0.1876, -0.0365,  0.0566,  0.0250],
        [-0.0526, -0.0259, -0.0420,  0.0302, -0.0365,  0.2383,  0.0330, -0.0044],
        [-0.0435, -0.1093,  0.0443,  0.0674,  0.0566,  0.0330,  0.1998, -0.0197],
        [ 0.0392,  0.0150,  0.0322, -0.0320,  0.0250, -0.0044, -0.0197,  0.2759]],
       device='cuda:0', dtype=torch.float64, grad_fn=<SelectBackward0>)
interval time: [328241.68210601807]
